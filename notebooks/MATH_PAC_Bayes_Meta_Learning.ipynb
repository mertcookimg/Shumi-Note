{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# メタ学習のPACベイズ\n",
    "\n",
    "参考\n",
    "* [PAC-Bayesian Meta-Learning: From Theory to Practice](https://arxiv.org/abs/2211.07206)\n",
    "\n",
    "\n",
    "\n",
    "* データの分布：$\\mathcal{D}$\n",
    "    * そのドメインを$\\mathcal{Z}$とする\n",
    "    * データから$m$個の観測をサンプルする：$S=\\{z_i\\}_{i=1}^m$ （$S \\sim \\mathcal{D}^m$で略記）\n",
    "* $z_i=(x_i, y_i)$：$x_i \\in \\mathcal{X}$は入力，$y_i \\in \\mathcal{Y}$は出力\n",
    "* ゴール：$S$を与えられたときに，仮説集合$\\mathcal{H}$から，新しい入力$x^* \\mathcal{D}_x$に対して予測をする仮説$h\\in \\mathcal{H}$を学習したい．\n",
    "    * 損失関数：$l: \\mathcal{H}\\times \\mathcal{Z}\\to \\mathbb{R}$\n",
    "    * 期待損失：$\\mathcal{L}(h, \\mathcal{D})=\\mathbb{E}_{z^*\\sim \\mathcal{D}} l(h, z^*)$\n",
    "    * 経験損失：$\\hat{\\mathcal{L}}(h, \\mathcal{D})=\\frac{1}{m}\\sum^{m}_{i=1}l(h, z^*)$\n",
    "* PACベイズでの仮説集合上の確率測度\n",
    "    * $P\\in \\mathcal{M}(\\mathcal{H})$：事前分布．データと独立．\n",
    "    * $Q\\in \\mathcal{M}(\\mathcal{H})$：事後分布．データに依存しても良い．\n",
    "    * Gibbs誤差：$\\mathcal{L}(Q, \\mathcal{D})=\\mathbb{E}_{h \\sim Q} \\mathcal{L}(h, \\mathcal{D})$\n",
    "        * その経験版：$\\hat{\\mathcal{L}}(Q, S)=\\mathbb{E}_{h \\sim Q} \\hat{\\mathcal{L}}(h, S)$\n",
    "* 中心キュムラント母関数：\n",
    "    * 確率変数$X$，分布$\\nu$，実関数$f$について，$\\Psi_{\\nu, f(\\cdot)}(t)=\\ln \\mathbb{E}_{X \\sim \\nu}\\left[e^{t(f(X)-\\mathbb{E}[f(X)])}\\right]$で定義される．\n",
    "    * $X\\sim \\nu$なる確率変数$f(X)$がどれだけその期待値から外れているかを表す量．$f(X)$がUnboundedなときの集中不等式で便利．\n",
    "  \n",
    "\n",
    "PACベイズのバウンドとして以下が知られています：\n",
    "\n",
    "---\n",
    "\n",
    "**Alquierのバウンド**\n",
    "\n",
    "$\\beta > 0$について，\n",
    "$$\n",
    "\\mathcal{L}(Q, \\mathcal{D}) \\leq \\hat{\\mathcal{L}}(Q, S)+\\frac{1}{\\beta}\\left[D_{K L}(Q \\| P)+\\ln \\frac{1}{\\delta}+\\Psi(\\beta, m)\\right]\n",
    "$$\n",
    "が成り立つ．ここで，$\\Psi(\\beta, m)=\\ln \\mathbb{E}_P \\mathbb{E}_{\\mathcal{D}^m} \\exp [\\beta(\\mathcal{L}(h, \\mathcal{D})-\\hat{\\mathcal{L}}(h, S))]$．\n",
    "\n",
    "$\\Psi$は$\\hat{\\mathcal{L}}$についての中心キュムラント母関数．これは一般に未知だが，損失関数が特定の形（Bdoundedなど）の場合，簡単にバウンド可能．\n",
    "\n",
    "---\n",
    "\n",
    "Alquierのバウンドの右辺を最小にするような事後分布$Q$は[Catoniのバウンド](MATH_PAC_Bayes.ipynb)で与えられます．\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## メタ学習\n",
    "\n",
    "メタ学習の設定\n",
    "* 学習者は事前分布$P$を所持し，新しいタスクに直面すると，そのデータ$S$を使って事後分布$Q$を得ます\n",
    "    * これは$Q(S, P)$として書く．ここで，$Q: \\mathcal{Z}^m \\times \\mathcal{M}(\\mathcal{H}) \\rightarrow \\mathcal{M}(\\mathcal{H})$\n",
    "    * メタ学習では，良い事前分布$P$をデータによって事前に学習するのが目標です．\n",
    "        * 学習用の$n$個のタスク$\\left\\{\\tau_1, \\ldots, \\tau_n\\right\\}$\n",
    "        * それぞれのタスクからは$m_i=m$個のデータをサンプルします．\n",
    "        * タスクは$\\tau_i \\sim \\mathcal{T}$からi.i.dにサンプルされます．\n",
    "* hyper-prior（事前分布の事前分布）：$\\mathcal{P} \\in \\mathcal{M}(\\mathcal{M}(\\mathcal{H}))$\n",
    "* hyper-posterior（事前分布の事後分布）：$\\mathcal{Q}$\n",
    "    * この性能は次の転移誤差で評価します：$\\mathcal{L}(\\mathcal{Q}, \\mathcal{T}):=\\mathbb{E}_{P \\sim \\mathcal{Q}}\\left[\\mathbb{E}_{(\\mathcal{D}, m) \\sim \\mathcal{T}}\\left[\\mathbb{E}_{S \\sim \\mathcal{D}^m}[\\mathcal{L}(Q(S, P), \\mathcal{D})]\\right]\\right]$\n",
    "    * 経験転移誤差：$\\hat{\\mathcal{L}}\\left(\\mathcal{Q}, S_1, \\ldots, S_n\\right):=\\mathbb{E}_{P \\sim \\mathcal{Q}}\\left[\\frac{1}{n} \\sum_{i=1}^n \\hat{\\mathcal{L}}\\left(Q\\left(S_i, P\\right), S_i\\right)\\right]$\n",
    "\n",
    "---\n",
    "\n",
    "**メタ学習のPACベイズバウンド**\n",
    "\n",
    "$\\delta \\in (0, 1]$に対して，\n",
    "\n",
    "$$\n",
    "\\begin{aligned}\n",
    "\\mathcal{L}(\\mathcal{Q}, \\mathcal{T}) \\leq & \\hat{\\mathcal{L}}\\left(\\mathcal{Q}, S_1, \\ldots, S_n\\right)+\\left(\\frac{1}{\\lambda}+\\frac{1}{n \\beta}\\right) D_{K L}(\\mathcal{Q} \\| \\mathcal{P}) \\\\\n",
    "& +\\frac{1}{n} \\sum_{i=1}^n \\frac{1}{\\beta} \\mathbb{E}_{P \\sim \\mathcal{Q}}\\left[D_{K L}\\left(Q\\left(S_i, P\\right) \\| P\\right)\\right]+\\underbrace{\\Psi^I(\\beta)+\\Psi^{I I}(\\lambda)+\\frac{1}{\\sqrt{n}} \\ln \\frac{1}{\\delta}}_{:=C(\\delta, \\lambda, \\beta)}\n",
    "\\end{aligned}\n",
    "$$\n",
    "\n",
    "が任意のhyper posterior$\\mathcal{Q} \\in \\mathcal{M}(\\mathcal{M}(\\mathcal{H}))$について，確率$1-\\delta$で成立します．\n",
    "ここで，\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100, 5)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "mu_T = 1 / 5\n",
    "sigma_T = 1 / 10\n",
    "\n",
    "d = 5\n",
    "datasize = 100\n",
    "\n",
    "w = \n",
    "x = np.random.randn(datasize, d)\n",
    "y = "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
