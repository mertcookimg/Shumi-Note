{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Linear MDPのサンプル効率の下界\n",
    "\n",
    "参考\n",
    "* [Confident Approximate Policy Iteration for Efficient Local Planning in qπ-realizable MDPs](https://arxiv.org/abs/2210.15755)\n",
    "\n",
    "Linear MDPで「良い解」を達成するために必要なサンプルは最低いくつ必要でしょうか？今回はそれを導出してみます。　\n",
    "\n",
    "表記\n",
    "* $d$次元ユークリッドボール：$\\mathcal{B}_d(L)=\\left\\{x \\in \\mathbb{R}^d:\\|x\\| \\leq L\\right\\}$\n",
    "* 特徴ベクトル：$\\varphi: \\mathcal{S} \\times \\mathcal{A} \\rightarrow \\mathcal{B}_d(L)$\n",
    "* 状態遷移マップ：$\\psi: \\mathcal{S} \\rightarrow \\mathbb{R}^d$\n",
    "    * $P\\left(s^{\\prime} \\mid s, a\\right)=\\left\\langle\\varphi(s, a), \\psi\\left(s^{\\prime}\\right)\\right\\rangle$\n",
    "    * $\\sum_{s \\in \\mathcal{S}}\\|\\psi(s)\\|_2 \\leq B$\n",
    "* 報酬マップ：$\\theta_r \\in \\mathcal{B}_d(B)$\n",
    "    * $r(s, a)=\\left\\langle\\varphi(s, a), \\theta_r\\right\\rangle$\n",
    "* $(\\alpha, \\delta)-$ sound planner：あるMDP $M$のシミュレータを使った時、almost surelyでplannerが停止し、かつplannerが$\\alpha$-optimalな方策を確率$1-\\delta$以上で出力する時、$(\\alpha, \\delta)-$ sound plannerと言う。\n",
    "\n",
    "このとき、次を証明します：\n",
    "\n",
    "---\n",
    "\n",
    "$\\delta \\in (0, 0.08]$, $\\gamma \\in [7/12, 1]$, $H=1 / (1 - \\gamma)$, \n",
    "$\\alpha \\in\\left(0,0.05 \\gamma H /(1+\\gamma)^2\\right]$,\n",
    "$d \\geq 3$とする。\n",
    "このとき、$(\\alpha, \\delta)$-soundなplannerを構築するために必要なクエリ複雑度は最低でも$\\Omega\\left(d^2 H^3 / \\alpha^2\\right)$である。\n",
    "\n",
    "---"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ムズMDPの構築\n",
    "\n",
    "MDPを次のように構築します：\n",
    "* $\\mathcal{S}=\\left\\{s_0, s_1\\right\\}$とし、$s_0$は初期状態\n",
    "* $\\mathcal{A}=\\{ \\pm 1 / \\sqrt{d-2}\\}^{d-2}$\n",
    "    * 例えば行動の一つは$[1 / \\sqrt{d-2}, -1 / \\sqrt{d-2}, 1 / \\sqrt{d-2}, 1 / \\sqrt{d-2}, \\dots]$みたいな感じ。\n",
    "* 任意の$a \\in \\mathcal{A}$について、\n",
    "$$\n",
    "\\varphi\\left(s_0, a\\right)=\\left(1,0, a^{\\top}\\right)^{\\top} \\quad \\text { and } \\quad \\varphi\\left(s_1, a\\right)=(0,1,0, \\ldots, 0)^{\\top}\n",
    "$$\n",
    "と特徴ベクトルを決める。\n",
    "\n",
    "また、後で遷移確率を適当な$\\beta \\in \\mathcal{A}$でパラメータ化する。そのため、MDPは$\\beta$でパラメータ化されており、$\\mathcal{M}=\\left\\{M_\\beta \\mid \\beta \\in \\mathcal{A}\\right\\}$とする。\n",
    "報酬ベクトルは以下で定義する：\n",
    "$$\\hat{\\theta}_r=(1,0, \\ldots, 0)^{\\top}$$\n",
    "よって、\n",
    "* 状態$s_0$の報酬：$r_\\beta\\left(s_0, a\\right)=\\left\\langle\\theta_r, \\varphi\\left(s_0, a\\right)\\right\\rangle=1$\n",
    "* 状態$s_1$の報酬：$r_\\beta\\left(s_1, a\\right)=\\left\\langle\\theta_r, \\varphi\\left(s_0, a\\right)\\right\\rangle=0$\n",
    "\n",
    "なので、ずっと$s_0$にいる方策が最適。\n",
    "\n",
    "遷移確率ベクトルは以下で定義する。$\\Delta=4(1+\\gamma)^2 \\alpha /\\left(\\gamma H^2\\right)$として、\n",
    "$$\\psi\\left(s_0\\right)=\\left(\\gamma, 0, \\Delta \\beta^{\\top}\\right)^{\\top} \\quad$$ \n",
    "および\n",
    "$$\\quad \\psi\\left(s_1\\right)=\\left(1-\\gamma, 1,-\\Delta \\beta^{\\top}\\right)^{\\top}$$\n",
    "\n",
    "このとき、\n",
    "\n",
    "$$\n",
    "\\begin{array}{ll}\n",
    "P_\\beta\\left(s_0 \\mid s_0, a\\right)=\\gamma+\\Delta \\beta^{\\top} a, & P_\\beta\\left(s_1 \\mid s_0, a\\right)=1-\\gamma-\\Delta \\beta^{\\top} a \\\\\n",
    "P_\\beta\\left(s_0 \\mid s_1, a\\right)=0, & P_\\beta\\left(s_1 \\mid s_1, a\\right)=1\n",
    "\\end{array}\n",
    "$$\n",
    "\n",
    "が成り立つ。\n",
    "よって、$a=\\beta$を選択すると$s_0$にいる可能性が一番高くなるので、$\\beta$が最適行動。\n",
    "\n",
    "このMDPをPythonで作ってみます。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import jax.numpy as jnp\n",
    "from itertools import product\n",
    "from jax.random import PRNGKey\n",
    "import jax\n",
    "from typing import NamedTuple, Optional\n",
    "\n",
    "key = PRNGKey(0)\n",
    "\n",
    "alpha = 0.01  # 最終的な方策の性能\n",
    "\n",
    "d = 5  # 特徴ベクトルのサイズ\n",
    "S = 2  # 状態集合のサイズ\n",
    "S_set = jnp.arange(S)  # 状態集合\n",
    "gamma = 0.9  # 割引率\n",
    "H = 1 / (1 - gamma)  # エフェクティブホライゾン\n",
    "\n",
    "# 行動集合を作ります\n",
    "A = 2 ** (d - 2)  # 行動集合のサイズ\n",
    "x = [[-1 / np.sqrt(d - 2), 1 / np.sqrt(d - 2)] for _ in range(d - 2)]\n",
    "A_set = jnp.array([a for a in product(*x)])  # 行動集合\n",
    "assert A == len(A_set)\n",
    "\n",
    "# MDPのパラメータβ。これが最適行動に相当します。\n",
    "beta_idx = 2\n",
    "beta = A_set[beta_idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 特徴ベクトルを作ります\n",
    "phi_s0 = jnp.concatenate((jnp.ones((A, 1)), jnp.zeros((A, 1))), axis=-1)\n",
    "phi_s0 = jnp.concatenate((phi_s0, A_set), axis=-1)\n",
    "assert jnp.all(phi_s0[0] == jnp.array([1, 0, *A_set[0]]))\n",
    "assert phi_s0.shape == (A, d)\n",
    "\n",
    "phi_s1 = jnp.zeros((A, d))\n",
    "phi_s1 = phi_s1.at[:, 1].set(1.0)\n",
    "assert phi_s1.shape == (A, d)\n",
    "\n",
    "phi = jnp.concatenate((phi_s0[None, :, :], phi_s1[None, :, :]), axis=0)\n",
    "assert phi.shape == (S, A, d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 報酬ベクトルを作ります\n",
    "theta_r = jnp.zeros(d)\n",
    "theta_r = theta_r.at[0].set(1.0)\n",
    "rew = phi @ theta_r\n",
    "\n",
    "# 遷移確率行列を作ります\n",
    "Delta = 4 * (1 + gamma) ** 2 * alpha / (gamma * H ** 2)\n",
    "psi_s0 = jnp.array([gamma, 0, *(Delta * beta)])\n",
    "assert psi_s0.shape == (d, )\n",
    "psi_s1 = jnp.array([1 - gamma, 1, *(-Delta * beta)])\n",
    "assert psi_s1.shape == (d, )\n",
    "\n",
    "P_to_s0 = phi @ psi_s0\n",
    "P_to_s1 = phi @ psi_s1\n",
    "P = jnp.concatenate((P_to_s0[:, :, None], P_to_s1[:, :, None]), axis=-1)\n",
    "assert P.shape == (S, A, S)\n",
    "np.testing.assert_allclose(P.sum(axis=-1), 1, atol=1e-6)  # ちゃんと確率行列になっているか確認します"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "状態数： 2\n",
      "行動数： 8\n",
      "割引率： 0.9\n",
      "ホライゾン： 10\n"
     ]
    }
   ],
   "source": [
    "# 状態集合, 行動集合, 割引率, 報酬行列, 遷移確率行列が準備できたのでMDPのクラスを作ります\n",
    "\n",
    "class MDP(NamedTuple):\n",
    "    S_set: jnp.array  # 状態集合\n",
    "    A_set: jnp.array  # 行動集合\n",
    "    gamma: float  # 割引率\n",
    "    H: int  # エフェクティブホライゾン\n",
    "    rew: jnp.array  # 報酬行列\n",
    "    P: jnp.array  # 遷移確率行列\n",
    "    optimal_Q: Optional[jnp.ndarray] = None  # 最適Q値\n",
    "\n",
    "    @property\n",
    "    def S(self) -> int:  # 状態空間のサイズ\n",
    "        return len(self.S_set)\n",
    "\n",
    "    @property\n",
    "    def A(self) -> int:  # 行動空間のサイズ\n",
    "        return len(self.A_set)\n",
    "\n",
    "\n",
    "H = int(1 / (1 - gamma))\n",
    "mdp = MDP(S_set, A_set, gamma, H, rew, P)\n",
    "\n",
    "print(\"状態数：\", mdp.S)\n",
    "print(\"行動数：\", mdp.A)\n",
    "print(\"割引率：\", mdp.gamma)\n",
    "print(\"ホライゾン：\", mdp.H)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "最適方策と最適価値関数も求めておきます。\n",
    "\n",
    "* ``compute_greedy_policy``: Q関数 ($S \\times A \\to \\mathcal{R}$) の貪欲方策を返します\n",
    "* ``compute_optimal_Q``: MDPの最適Q関数 $q_* : S \\times A \\to \\mathcal{R}$ を返します。\n",
    "* ``compute_policy_Q``: 方策 $\\pi$ のQ関数 $q_\\pi : S \\times A \\to \\mathcal{R}$ を返します。\n",
    "* ``compute_policy_matrix``: 方策$\\pi$の行列${\\Pi}^{\\pi}$を返します。\n",
    "* ``compute_policy_visit_sa``: 方策 $\\pi$ の割引訪問頻度１${d}^\\pi_\\mu \\in \\mathbb{R}^{S\\times A}$ を返します。\n",
    "* ``compute_policy_visit_s``: 方策 $\\pi$ の割引訪問頻度２$\\bar{d}^\\pi_\\mu \\in \\mathbb{R}^{S}$ を返します。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "import jax\n",
    "import jax.numpy as jnp\n",
    "import numpy as np\n",
    "from functools import partial\n",
    "import chex\n",
    "\n",
    "\n",
    "@jax.jit\n",
    "def compute_greedy_policy(Q: jnp.ndarray):\n",
    "    \"\"\"Q関数の貪欲方策を返します\n",
    "\n",
    "    Args:\n",
    "        Q (jnp.ndarray): (SxA)の行列\n",
    "\n",
    "    Returns:\n",
    "        greedy_policy (jnp.ndarray): (SxA)の行列\n",
    "    \"\"\"\n",
    "    greedy_policy = jnp.zeros_like(Q)\n",
    "    S, A = Q.shape\n",
    "    greedy_policy = greedy_policy.at[jnp.arange(S), Q.argmax(axis=1)].set(1)\n",
    "    assert greedy_policy.shape == (S, A)\n",
    "    return greedy_policy\n",
    "\n",
    "\n",
    "@partial(jax.jit, static_argnames=(\"S\", \"A\"))\n",
    "def _compute_optimal_Q(mdp: MDP, S: int, A: int):\n",
    "    \"\"\"MDPについて、ベルマン最適作用素を複数回走らせて最適価値関数を動的計画法で計算します。\n",
    "    Args:\n",
    "        mdp (MDP)\n",
    "\n",
    "    Returns:\n",
    "        optimal_Q (jnp.ndarray): (SxA)の行列\n",
    "    \"\"\"\n",
    "\n",
    "    def backup(optimal_Q):\n",
    "        next_v = mdp.P @ optimal_Q.max(axis=1)\n",
    "        assert next_v.shape == (S, A)\n",
    "        return mdp.rew + mdp.gamma * next_v\n",
    "    \n",
    "    optimal_Q = jnp.zeros((S, A))\n",
    "    body_fn = lambda i, Q: backup(Q)\n",
    "    return jax.lax.fori_loop(0, mdp.H + 100, body_fn, optimal_Q)\n",
    "\n",
    "compute_optimal_Q = lambda mdp: _compute_optimal_Q(mdp, mdp.S, mdp.A)\n",
    "\n",
    "\n",
    "@jax.jit\n",
    "def compute_policy_Q(mdp: MDP, policy: jnp.ndarray):\n",
    "    \"\"\"MDPと方策について、ベルマン期待作用素を複数回走らせて価値関数を動的計画法で計算します。\n",
    "    Args:\n",
    "        mdp (MDP)\n",
    "        policy (jnp.ndarray): (SxA)の行列\n",
    "\n",
    "    Returns:\n",
    "        optimal_Q (jnp.ndarray): (SxA)の行列\n",
    "    \"\"\"\n",
    "    S, A = policy.shape\n",
    "    chex.assert_shape(policy, (mdp.S, mdp.A))\n",
    "\n",
    "    def backup(policy_Q):\n",
    "        max_Q = (policy * policy_Q).sum(axis=1)\n",
    "        next_v = mdp.P @ max_Q\n",
    "        assert next_v.shape == (S, A)\n",
    "        return mdp.rew + mdp.gamma * next_v\n",
    "    \n",
    "    policy_Q = jnp.zeros((S, A))\n",
    "    body_fn = lambda i, Q: backup(Q)\n",
    "    return jax.lax.fori_loop(0, mdp.H + 100, body_fn, policy_Q)\n",
    "\n",
    "\n",
    "@jax.jit\n",
    "def compute_policy_matrix(policy: jnp.ndarray):\n",
    "    \"\"\"\n",
    "    上で定義した方策行列を計算します。方策についての内積が取りたいときに便利です。\n",
    "    Args:\n",
    "        policy (jnp.ndarray): (SxA)の行列\n",
    "\n",
    "    Returns:\n",
    "        policy_matrix (jnp.ndarray): (SxSA)の行列\n",
    "    \"\"\"\n",
    "    S, A = policy.shape\n",
    "    PI = policy.reshape(1, S, A)\n",
    "    PI = jnp.tile(PI, (S, 1, 1))\n",
    "    eyes = jnp.eye(S).reshape(S, S, 1)\n",
    "    PI = (eyes * PI).reshape(S, S*A)\n",
    "    return PI\n",
    "\n",
    "\n",
    "@jax.jit\n",
    "def compute_policy_visit_sa(mdp: MDP, policy: jnp.ndarray, init_dist: jnp.ndarray):\n",
    "    \"\"\"MDPと方策について、割引訪問頻度１を動的計画法で計算します。\n",
    "    Args:\n",
    "        mdp (MDP)\n",
    "        policy (jnp.ndarray): (SxA)の行列\n",
    "        init_dist (jnp.ndarray): (S) 初期状態の分布\n",
    "\n",
    "    Returns:\n",
    "        visit (jnp.ndarray): (SxA)の行列\n",
    "    \"\"\"\n",
    "    S, A = policy.shape\n",
    "    chex.assert_shape(policy, (mdp.S, mdp.A))\n",
    "    Pi = compute_policy_matrix(policy)\n",
    "    PPi = mdp.P.reshape(S*A, S) @ Pi \n",
    "\n",
    "    def backup(visit):\n",
    "        next_visit = mdp.gamma * visit @ PPi\n",
    "        return init_dist @ Pi + next_visit\n",
    "    \n",
    "    body_fn = lambda i, visit: backup(visit)\n",
    "    visit = jnp.zeros(S*A)\n",
    "    visit = jax.lax.fori_loop(0, mdp.H + 100, body_fn, visit)\n",
    "    visit = visit.reshape(S, A)\n",
    "    return visit\n",
    "\n",
    "\n",
    "@jax.jit\n",
    "def compute_policy_visit_s(mdp: MDP, policy: jnp.ndarray, init_dist: jnp.ndarray):\n",
    "    \"\"\"MDPと方策について、割引訪問頻度２を動的計画法で計算します。\n",
    "    Args:\n",
    "        mdp (MDP)\n",
    "        policy (jnp.ndarray): (SxA)の行列\n",
    "        init_dist (jnp.ndarray): (S) 初期状態の分布\n",
    "\n",
    "    Returns:\n",
    "        visit (jnp.ndarray): (S)のベクトル\n",
    "    \"\"\"\n",
    "    S, A = policy.shape\n",
    "    chex.assert_shape(policy, (mdp.S, mdp.A))\n",
    "    Pi = compute_policy_matrix(policy)\n",
    "    PiP = Pi @ mdp.P.reshape(S*A, S) \n",
    "\n",
    "    def backup(visit):\n",
    "        next_visit = mdp.gamma * visit @ PiP\n",
    "        return init_dist + next_visit\n",
    "    \n",
    "    body_fn = lambda i, visit: backup(visit)\n",
    "    visit = jnp.zeros(S)\n",
    "    visit = jax.lax.fori_loop(0, mdp.H + 100, body_fn, visit)\n",
    "    return visit\n",
    "\n",
    "\n",
    "# 動的計画法による最適価値関数\n",
    "optimal_Q_DP = compute_optimal_Q(mdp)\n",
    "optimal_V_DP = optimal_Q_DP.max(axis=1)\n",
    "optimal_policy = compute_greedy_policy(optimal_Q_DP)\n",
    "mdp = mdp._replace(optimal_Q=optimal_Q_DP)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0, 0.5, 'Estimation Gap')"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAArMAAAEmCAYAAABxpBh2AAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjYuMywgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/P9b71AAAACXBIWXMAAA9hAAAPYQGoP6dpAAA9XUlEQVR4nO3de1hU9boH8O8MMAMIDKAyaIKgoqioeSlDu1ih5i1Nd2mHFNHqWHhBcmfstte9EWzvvJW30zGwUtm500wrPIqKWxNFFLemUnkJtgqkxs3LoDPr/IGsHC42w8yaNTN8P88zz8OstWatdxm9vv7m/f2WQhAEAUREREREDkgpdwBERERERI3FYpaIiIiIHBaLWSIiIiJyWCxmiYiIiMhhsZglIiIiIofFYpaIiIiIHBaLWSIiIiJyWCxmiYiIiMhhucodgNQMBgMuX74Mb29vKBQKucMhIickCAIqKirQunVrKJXON0bAPEpEUrMkjzp9MXv58mUEBQXJHQYRNQGFhYVo06aN3GFYHfMoEdlKY/Ko0xez3t7eAKr/cHx8fGSOhoicUXl5OYKCgsR842yYR4lIapbkUacvZmu+EvPx8WESJiJJOetX8MyjRGQrjcmjztfcRURERERNBotZIiIiInJYLGaJiIiIyGGxmCUiIiIih8ViloiIiIgcFotZIiIiInJYLGZr2f/DL3hu2X7M2nxC7lCIiBxS4fWbeG7ZfoxedVDuUIioCXD6dWbNVXH7Ls4WVcDHw03uUIiIHNIdvQFniyrg7c6/YohIehyZJSIiq1LeW/RcEGQOhIiaBBazDWESJiJqlJpi1sBqlohsgMVsLU76NEoiIpupyaOsZYnIFljMEhGRVdUUsxyZJSJbYDHbAIF9BkREjcKeWSKyJRaztbDLgIjIMuyZJSJbYjFLRERWpWSbARHZEIvZBjAHE5GzmD9/PhQKhdErPDxcsuspxJFZyS5BRCTiita1cDUDInJGXbt2xe7du8X3rq7Spf/786ggCGJxS0QkBRazRERNgKurKwIDA21yLeV9xasgcJCAiKTFNoMG8NsxInImP/74I1q3bo127dohOjoaBQUFDR6r0+lQXl5u9DKH8r7ilX2zRCQ1FrN1cAiBiJxL3759kZaWhoyMDKxevRoXLlzAE088gYqKinqPT05OhkajEV9BQUFmXe/+tgL2zRKR1FjMEhE5uSFDhuDFF19E9+7dMXjwYHzzzTcoLS3F559/Xu/xiYmJKCsrE1+FhYVmXY8js0RkS+yZJSJqYnx9fdGxY0f89NNP9e5Xq9VQq9WNPn/tnlkiIinZzchsSkoKFAoF4uPjxW23b99GXFwcmjdvDi8vL4wZMwbFxcU2iUdgBiYiJ1VZWYlz586hVatWkpzfaDUDzkAgIonZRTGbk5ODtWvXonv37kbbZ86cie3bt2Pz5s3IysrC5cuXMXr0aElj4axbInI2s2bNQlZWFi5evIjvvvsOL7zwAlxcXPDyyy9Lcj0le2aJyIZkL2YrKysRHR2Njz76CH5+fuL2srIyrFu3DkuWLMEzzzyD3r17IzU1Fd999x2ys7NljJiIyLH85z//wcsvv4xOnTrhpZdeQvPmzZGdnY2WLVtKcj0Fe2aJyIZk75mNi4vDsGHDEBUVhb/+9a/i9tzcXNy5cwdRUVHitvDwcAQHB+PQoUN47LHHJI2L6ZeInEV6erpNr2fUM2uw6aWJqAmStZhNT0/HsWPHkJOTU2dfUVERVCoVfH19jbZrtVoUFRU1eE6dTgedTie+N3d9RHYZEBFZxrjNgEMDRCQt2doMCgsLMWPGDGzYsAHu7u5WO6+l6yMSEZFluDQXEdmSbMVsbm4uSkpK0KtXL7i6usLV1RVZWVlYsWIFXF1dodVqUVVVhdLSUqPPFRcXP/CRjJauj1iD+ZeIqHHuf2gCUykRSU22NoNnn30WJ0+eNNoWGxuL8PBwzJ49G0FBQXBzc0NmZibGjBkDAMjPz0dBQQEiIyMbPK+l6yMquJwBEZHFFIrqQQGOzBKR1GQrZr29vREREWG0rVmzZmjevLm4ffLkyUhISIC/vz98fHwwbdo0REZGSj75i4iILKNUKKAXBH7LRUSSk301gwdZunQplEolxowZA51Oh8GDB2PVqlU2uTbzLxFR4ykVgB4cmSUi6dlVMbtv3z6j9+7u7li5ciVWrlxpsxjYZEBEZLnqli2BD00gIsnJ/tAEIiJyPjUrGhhYzRKRxFjMNoRfjRERNZqSk2mJyEZYzNbC/EtEZLmaVMqeWSKSGotZIiKyupqRWXYZEJHUWMwSEZHV1XzLxZFZIpIai9kGMP0SETWe8t4MMIHFLBFJjMVsLeyZJSKyXE2bAWtZIpIai1kiIrI6cWkuFrNEJDEWsw3gaAIRkSVqJoAxmRKRtFjM1qLgM8CIiCym5AQwIrIRFrNERGR17JklIlthMdsAgesZEBE1GkdmichWWMzWxi4DIiKLKTgyS0Q2wmKWiIisTnnvbxeOzBKR1FjMNoD5l4io8RTg42yJyDZYzNbCLgMiIsvV9MzyCWBEJDUWs0REZHU1qxlwZJaIpMZitgEcTCAiajwFVzMgIhthMVtLzQxcIiJqPK4zS0S2wmKWiIis7rdiltUsEUmLxSwREVndb20G8sZBRM6PxWwDmH+JiBpPIU4AYzYlImmxmK2FHbNE5MxSUlKgUCgQHx8v6XX4OFsishUWs0RETUROTg7Wrl2L7t27S34tTgAjIlthMdsATlogImdSWVmJ6OhofPTRR/Dz85P8euJDE9i0RUQSYzFbC1fmIiJnFBcXh2HDhiEqKup3j9XpdCgvLzd6mUvsmTWY/VEiIrO4yh0AERFJKz09HceOHUNOTo5JxycnJ2PBggUWXZM9s0RkKxyZJSJyYoWFhZgxYwY2bNgAd3d3kz6TmJiIsrIy8VVYWGj2dRV8nC0R2UijRmb1ej22bt2KM2fOAAA6d+6MUaNGwdXV8Qd6FVzPgIjsRH5+Pj744AOjXDtt2jR06tTJ5HPk5uaipKQEvXr1Erfp9Xrs378fH374IXQ6HVxcXIw+o1aroVarLYpd7JnlyCwRSczs6vP777/H888/j6KiIjGhLl68GC1btsT27dsRERFh9SCJiJqaL774AuPGjUOfPn0QGRkJAMjOzkZERATS09MxZswYk87z7LPP4uTJk0bbYmNjER4ejtmzZ9cpZK2FI7NEZCtmF7OvvvoqunbtiqNHj4ozYn/99VdMnDgRr7/+Or777jurBykHDiYQkZzefvttJCYmYuHChUbb582bh7ffftvkYtbb27vOIEOzZs3QvHlzSQcfuJoBEdmK2T2zeXl5SE5ONlraxc/PD0lJSTh+/LhVg5MDVzMgIntw5coVTJgwoc72V155BVeuXJEhIvMoOTJLRDZi9shsx44dUVxcjK5duxptLykpQYcOHawWGBFRUzZgwAD861//qpNXDxw4gCeeeMKic+/bt8+iz5vit4cmsJolImmZXcwmJydj+vTpmD9/Ph577DEA1X1cCxcuxOLFi43WI/Tx8bFepDbGr8aISE7PP/88Zs+ejdzcXKNcu3nzZixYsABfffWV0bH2RsGluYjIRswuZocPHw4AeOmll8QG/5p/eY8YMUJ8r1AooNfrrRWnzbDLgIjswZtvvgkAWLVqFVatWlXvPgB2m2v50AQishWzi9m9e/dKEQcREd3H4OBVIB+aQES2YnYx+9RTT0kRBxERORGxZ1bmOIjI+TX6KQc3b95EQUEBqqqqjLZ3797d5HOsXr0aq1evxsWLFwEAXbt2xdy5czFkyBAAwO3bt/HWW28hPT0dOp0OgwcPxqpVq6DVahsbtsk4mEBEcrtx4waysrLqzbXTp0+XKSrT8KEJRGQrZhezv/zyC2JjY/Htt9/Wu9+c3q02bdogJSUFYWFhEAQB69evx8iRI3H8+HF07doVM2fOxNdff43NmzdDo9Fg6tSpGD16NA4ePGhu2KZj0ywR2YHjx49j6NChuHnzJm7cuAF/f39cvXoVnp6eCAgIsPtilg9NICJbMXud2fj4eJSWluLw4cPw8PBARkYG1q9fj7CwMKPZtaYYMWIEhg4dirCwMHTs2BFJSUnw8vJCdnY2ysrKsG7dOixZsgTPPPMMevfujdTUVHz33XfIzs42N2wiIocyc+ZMjBgxAr/++is8PDyQnZ2Nn3/+Gb1798bf//53ucP7XeyZJSJbMXtkds+ePdi2bRv69OkDpVKJtm3bYuDAgfDx8UFycjKGDRvWqED0ej02b96MGzduIDIyErm5ubhz5w6ioqLEY8LDwxEcHIxDhw6JS9XUptPpoNPpxPf3LxVmDqZfIpJTXl4e1q5dC6VSCRcXF+h0OrRr1w7vvfceYmJiMHr0aLlDfCAFODJLRLZh9sjsjRs3EBAQAKD6yV+//PILAKBbt244duyY2QGcPHkSXl5eUKvVmDJlCrZu3YouXbqgqKgIKpUKvr6+RsdrtVoUFRU1eL7k5GRoNBrxFRQUZFY8CvYZEJEdcHNzg1JZnaIDAgJQUFAAANBoNCgsLJQzNJMoa/524cgsEUnM7GK2U6dOyM/PBwD06NEDa9euxaVLl7BmzRq0atXK7AA6deqEvLw8HD58GG+88QZiYmJw+vRps89TIzExEWVlZeLLEZI+EVFtPXv2RE5ODoDqVWTmzp2LDRs2ID4+HhERETJH9/vYM0tEtmJ2m8GMGTPE54LPmzcPzz33HDZs2ACVSoW0tDSzA1CpVOLjGnv37o2cnBwsX74cY8eORVVVFUpLS41GZ4uLixEYGNjg+dRqNdRqtdlx1MYZuEQkp0WLFqGiogIAkJSUhAkTJuCNN95AWFgYPv74Y5mj+31KsZhlLiUiaZldzL7yyiviz71798bPP/+Ms2fPIjg4GC1atLA4IIPBAJ1Oh969e8PNzQ2ZmZkYM2YMACA/Px8FBQWIjIy0+DoNUbDLgIjsQJ8+fcSfAwICkJGRIWM05vttApi8cRCR82v0OrM1PD090atXr0Z9NjExEUOGDEFwcDAqKiqwceNG7Nu3Dzt37oRGo8HkyZORkJAAf39/+Pj4YNq0aYiMjGxw8hcREdkHcWSW1SwRSczkYra0tBSbNm3CG2+8AQCIjo7GrVu3xP0uLi746KOP6kzYepCSkhJMmDABV65cgUajQffu3bFz504MHDgQALB06VIolUqMGTPG6KEJtsD0S0RyOHfuHJKSksRWguDgYFRWVor7XVxccODAAXTq1EmuEE1S8y2XwGxKRBIzuZj96KOPkJeXJxazX331FQYPHgxvb28AwKFDh7Bs2TLMnz/f5IuvW7fugfvd3d2xcuVKrFy50uRzWopdBkQkpw8++MDoKYe//vor5s6dK64i849//ANLly7FmjVr5ArRJDUjs3qDzIEQkdMzuZj95z//iaSkJKNt7733Htq1awcA2Lp1KxYuXGhWMUtERMYyMzPr/EN/zJgxYq4NCQnBq6++KkdoZnHhBDAishGTl+Y6f/680ddanTp1gkqlEt/36NEDP/74o3WjkxPzLxHJ4OLFi2jdurX4/tVXX4VGoxHfh4SE4D//+Y8coZlFqawZmWUyJSJpmVzM3rhxA2VlZeL7o0ePok2bNkb7DQbH/z5JweUMiEhGSqUSly9fFt8vXboUzZs3F98XFxfDzc1NjtDM4nLvbxcWs0QkNZOL2Xbt2j3wCV9Hjx5FaGioVYIiImqqunbtit27dze4f+fOnQ7x0ISanlmu2U1EUjO5mH3hhRfw5z//GcXFxXX2FRUVYd68eXjhhResGhwRUVMTGxuLpKQkfP3113X2bd++HSkpKYiNjZUhMvOIE8BYzBKRxEyeAPb222/jiy++QFhYGMaPH4+OHTsCqH6QwWeffYaHHnoIs2fPlixQW2P6JSI5vPbaa9izZw9GjBiB8PBwca5Cfn4+8vPzMWbMGLz22msyR/n7XJRczYCIbMPkYtbb2xsHDx5EYmIiNm3ahNLSUgCAr68v/uu//guLFi0Sl+lyZGyZJSK5bdq0CSNHjkR6ejry8/MBAGFhYZg7dy7GjRsnc3SmqSlmuZoBEUnNrCeA+fn5Yc2aNVi9ejV++eUXAEDLli05aYqIyMrGjRvnMIVrffgEMCKylUY9zlahUIgLeDsrTlogImq8ewOz7JklIsmZPAGsqeAYMxGR5cQ2A47MEpHEWMwSEZHVcTUDIrIVFrMNYPolImq83yaAyRwIETk9s4vZ8+fPSxGH3eBcNiIiy9X0zLLNgIikZnYx26FDBzz99NP47LPPcPv2bSliIiJq8m7cuIE5c+agX79+6NChA9q1a2f0Msfq1avRvXt3+Pj4wMfHB5GRkfj2228liryaUlxnlsUsEUnL7NUMjh07htTUVCQkJGDq1KkYO3YsJk+ejEcffVSK+GTDNi8iktOrr76KrKwsjB8/Hq1atbJoCcQ2bdogJSUFYWFhEAQB69evx8iRI3H8+HF07drVilH/xoU9s0RkI2YXsw8//DCWL1+O999/H1999RXS0tLw+OOPo2PHjpg0aRLGjx+Pli1bShGrjbDPgIjk9+233+Lrr79G//79LT7XiBEjjN4nJSVh9erVyM7Olq6Y5WoGRGQjjZ4A5urqitGjR2Pz5s1YvHgxfvrpJ8yaNQtBQUGYMGECrly5Ys04iYiaFD8/P/j7+1v9vHq9Hunp6bhx4wYiIyPrPUan06G8vNzoZS7xoQmsZYlIYo0uZo8ePYo333wTrVq1wpIlSzBr1iycO3cOu3btwuXLlzFy5EhrxmlzAtczICIZ/eUvf8HcuXNx8+ZNq5zv5MmT8PLyglqtxpQpU7B161Z06dKl3mOTk5Oh0WjEV1BQkNnX40MTiMhWzG4zWLJkCVJTU5Gfn4+hQ4fik08+wdChQ6FUVtfFoaGhSEtLQ0hIiLVjtQmuZkBE9uD999/HuXPnoNVqERISAjc3N6P9x44dM+t8nTp1Ql5eHsrKyvDPf/4TMTExyMrKqregTUxMREJCgvi+vLzc7IKWbQZEZCtmF7OrV6/GpEmTMHHiRLRq1areYwICArBu3TqLgyMiaqpGjRpl1fOpVCp06NABANC7d2/k5ORg+fLlWLt2bZ1j1Wo11Gq1RdfjagZEZCtmF7O7du1CcHCwOBJbQxAEFBYWIjg4GCqVCjExMVYLkoioqZk3b56k5zcYDNDpdJKd34U9s0RkI2YXs+3bt8eVK1cQEBBgtP369esIDQ2FXq+3WnByYpsXEdmD3NxcnDlzBgDQtWtX9OzZ0+xzJCYmYsiQIQgODkZFRQU2btyIffv2YefOndYOV/TbBDAmUyKSltnFrNBAYqqsrIS7u7vFAcmNLbNEZA9KSkowbtw47Nu3D76+vgCA0tJSPP3000hPTzdrCcSSkhJxlRmNRoPu3btj586dGDhwoETRs82AiGzH5GK2ZjKAQqHA3Llz4enpKe7T6/U4fPgwHn74YasHSETUFE2bNg0VFRX4/vvv0blzZwDA6dOnERMTg+nTp2PTpk0mn0uOOQwu9zrRODJLRFIzuZg9fvw4gOqR2ZMnT0KlUon7VCoVevTogVmzZlk/Qpkw/xKRnDIyMrB7926xkAWALl26YOXKlRg0aJCMkZmmps2AI7NEJDWTi9m9e/cCAGJjY7F8+XL4+PhIFpScLHlkJBGRtRgMhjrLcQGAm5sbDAaDDBGZR1yaiyMDRCQxsx+akJqa6rSFLBGRvXjmmWcwY8YMXL58Wdx26dIlzJw5E88++6yMkZlGnABm/3U3ETk4k0ZmR48ejbS0NPj4+GD06NEPPHbLli1WCYyIqCn78MMP8fzzzyMkJER8YEFhYSEiIiLw2WefyRzd7xPbDDgyS0QSM6mY1Wg04tfvGo1G0oDkxiYDIrIHQUFBOHbsGHbv3o2zZ88CADp37oyoqCiZIzONC1czICIbMamYTU1NrfdnIiKSjkKhwMCBAyVdQksqNasZNLScIxGRtZi9zmxTwQRMRLa2YsUKvP7663B3d8eKFSseeOz06dNtFFXjKNhmQEQ2YlIx27NnT5Nn+R87dsyigOTGxQyISC5Lly5FdHQ03N3dsXTp0gaPUygUdl/MuohLc8kcCBE5PZOK2VGjRkkcBhERXbhwod6fHZG4NBd7ZolIYiYVs/PmzZM6DrvD9EtEclq4cCFmzZpl9LRFALh16xb+9re/Ye7cuTJFZhquZkBEtmL2OrPOTsH1DIjIDixYsACVlZV1tt+8eRMLFiyQISLz3BuY5UMTiEhyZk8A0+v1WLp0KT7//HMUFBSgqqrKaP/169etFhwRUVMlCEK9cxVOnDgBf39/GSIyD9sMiMhWzB6ZXbBgAZYsWYKxY8eirKwMCQkJGD16NJRKJebPny9BiERETYefnx/8/f2hUCjQsWNH+Pv7iy+NRoOBAwfipZdekjvM36VUss2AiGzD7JHZDRs24KOPPsKwYcMwf/58vPzyy2jfvj26d++O7Oxss2bYJicnY8uWLTh79iw8PDzQr18/LF68GJ06dRKPuX37Nt566y2kp6dDp9Nh8ODBWLVqFbRarbmhm4X5l4jksGzZMgiCgEmTJmHBggVGD6pRqVQICQlBZGSkjBGaxoWPsyUiGzG7mC0qKkK3bt0AAF5eXigrKwMADB8+HHPmzDHrXFlZWYiLi8MjjzyCu3fv4k9/+hMGDRqE06dPo1mzZgCAmTNn4uuvv8bmzZuh0WgwdepUjB49GgcPHjQ3dJNwaS4iklNMTAwAIDQ0FP369YObm5vMETWO2GbAkQEikpjZxWybNm1w5coVBAcHo3379vi///s/9OrVCzk5OVCr1WadKyMjw+h9WloaAgICkJubiyeffBJlZWVYt24dNm7ciGeeeQZA9RPIOnfujOzsbDz22GPmhk9E5BCeeuop8efbt2/XmZ/g4+Nj65DMUjMwwMfZEpHUzO6ZfeGFF5CZmQkAmDZtGubMmYOwsDBMmDABkyZNsiiYmlHemskNubm5uHPnjtGzyMPDwxEcHIxDhw7Vew6dTofy8nKjV2MIXJyLiGR08+ZNTJ06FQEBAWjWrBn8/PyMXvaOI7NEZCtmj8ympKSIP48dO1YsLMPCwjBixIhGB2IwGBAfH4/+/fsjIiICQHVLg0qlgq+vr9GxWq0WRUVF9Z4nOTnZIZatISJ6kD/+8Y/Yu3cvVq9ejfHjx2PlypW4dOkS1q5da5SH7dVvTwBjMUtE0jK7mK0tMjLSKpMR4uLicOrUKRw4cMCi8yQmJiIhIUF8X15ejqCgIEvDIyKyqe3bt+OTTz7BgAEDEBsbiyeeeAIdOnRA27ZtsWHDBkRHR8sd4gMpxZFZmQMhIqfXqGL28uXLOHDgAEpKSmCoNVW1Mc8Lnzp1Knbs2IH9+/ejTZs24vbAwEBUVVWhtLTUaHS2uLgYgYGB9Z5LrVab3btbH34zRkRyun79Otq1aweguj+2Zg3vxx9/HG+88YacoZlEqeA6s0RkG2YXs2lpafjv//5vqFQqNG/e3GhRb4VCYVYxKwgCpk2bhq1bt2Lfvn0IDQ012t+7d2+4ubkhMzMTY8aMAQDk5+ejoKBAsqVpuJoBEdmDdu3a4cKFCwgODkZ4eDg+//xzPProo9i+fXud1it75MLH2RKRjZhdzM6ZMwdz585FYmIilErLnoYbFxeHjRs3Ytu2bfD29hb7YDUaDTw8PKDRaDB58mQkJCTA398fPj4+mDZtGiIjI7mSARE5tdjYWJw4cQJPPfUU3nnnHYwYMQIffvgh7ty5gyVLlsgd3u9ycakuZu9yZJaIJGZ2MXvz5k2MGzfO4kIWAFavXg0AGDBggNH21NRUTJw4EQCwdOlSKJVKjBkzxuihCVJj+iUiOc2cOVP8OSoqCmfPnkVubi46dOiA7t27yxiZaVz5OFsishGzi9nJkydj8+bNeOeddyy+uGDC10/u7u5YuXIlVq5cafH1TKEA+wyIyP60bdsWbdu2lTsMk9UszXXXIEAQBKOWNCIiazK7mE1OTsbw4cORkZGBbt261Xk6jSN8/UVE5AhycnKwd+/eeifb2nuurRmZBaqX53J1YTFLRNJoVDG7c+dOdOrUCQDqTABzFpyzQERyWrRoEf785z+jU6dO0Gq1DpdrXV1+a0W7axDg6iJjMETk1MwuZt9//318/PHHYk+rs3GAvyOIqAlYvny5Q+fa2iOzRERSMXsWl1qtRv/+/aWIhYiI7lEqlQ6da13uK2bv6lnMEpF0zC5mZ8yYgQ8++ECKWIiI6J6ZM2fabOKrFFzu+5rrbq1+XyIiazK7zeDIkSPYs2cPduzYga5du9aZALZlyxarBScvjiQQkXxmzZqFYcOGoX379ujSpYtFuTY5ORlbtmzB2bNn4eHhgX79+mHx4sXi3AcpKJUKKBXVj7NlmwERScnsYtbX1xejR4+WIha7wJ5ZIrIH06dPx969e/H000/XedqiubKyshAXF4dHHnkEd+/exZ/+9CcMGjQIp0+fRrNmzawYtTFXFyWq7hr44AQikpTZxWxqaqoUcRAR0X3Wr1+PL774AsOGDbP4XBkZGUbv09LSEBAQgNzcXDz55JMWn78hrkoFqsCeWSKSltnFbFPBpbmISE7+/v5o3769JOcuKysTr1EfnU4HnU4nvi8vL2/UdX57cAJ7ZolIOiYVs7169UJmZib8/PzQs2fPB37ddezYMasFJwc+AYyI7MH8+fMxb948pKamwtPT02rnNRgMiI+PR//+/REREVHvMcnJyViwYIHF16pZnos9s0QkJZOK2ZEjR0KtVos/O8KC3UREjmzFihU4d+4ctFotQkJC6kwAa+zAQVxcHE6dOoUDBw40eExiYiISEhLE9+Xl5QgKCjL7Wi7K6gVz2DNLRFIyqZidN2+e+PP8+fOlisWuMPUSkZxGjRpl9XNOnToVO3bswP79+9GmTZsGj1Or1eIAhiXcXDgyS0TSM7tntl27dsjJyUHz5s2NtpeWlqJXr144f/681YKTAwedicge3D+IYClBEDBt2jRs3boV+/btQ2hoqNXO/SA1PbN39OyZJSLpmF3MXrx4EXq9vs52nU6H//znP1YJioiIrCcuLg4bN27Etm3b4O3tjaKiIgCARqOBh4eHZNdlzywR2YLJxexXX30l/rxz505oNBrxvV6vR2Zmps3+tW8LApczICIb8/f3xw8//IAWLVrAz8/vgfMTrl+/bvJ5V69eDQAYMGCA0fbU1FRMnDixMaGa5LfVDJhPiUg6JhezNf1bCoUCMTExRvvc3NwQEhKC999/36rByYFdBkQkl6VLl8Lb21v82VqTbeX6x7mbS/UEMI7MEpGUTC5mDffWCQwNDUVOTg5atGghWVBERE3R/QMFUo6Y2gp7ZonIFpTmfuDChQtNopDlOAIRycnFxQUlJSV1tl+7dg0uLi4yRGQ+9swSkS2YXcwCQGZmJoYPH4727dujffv2GD58OHbv3m3t2GTB1QyIyB401Bqg0+mgUqlsHE3jsGeWiGzB7NUMVq1ahRkzZuAPf/gDZsyYAQDIzs7G0KFDsXTpUsTFxVk9SCKipmLFihUAqucn/O///i+8vLzEfXq9Hvv370d4eLhc4ZnFVcmeWSKSntnF7KJFi7B06VJMnTpV3DZ9+nT0798fixYtYjFLRGSBpUuXAqgemV2zZo1RS4FKpUJISAjWrFkjV3hmcXVhzywRSc/sYra0tBTPPfdcne2DBg3C7NmzrRKUPeDKXEQkhwsXLgAAnn76aWzZsgV+fn4yR9R4LuyZJSIbMLtn9vnnn8fWrVvrbN+2bRuGDx9ulaDkxaZZIpLf3r17jQpZvV6PvLw8/PrrrzJGZR5X9swSkQ2YPTLbpUsXJCUlYd++fYiMjARQ3TN78OBBvPXWW2K/F1DdfkBEROaLj49Ht27dMHnyZOj1ejz55JM4dOgQPD09sWPHjjoPQLBHLuyZJSIbMLuYXbduHfz8/HD69GmcPn1a3O7r64t169aJ7xUKhUMXs3wCGBHJafPmzXjllVcAANu3b8fFixdx9uxZfPrpp3j33Xdx8OBBmSP8feLILHtmiUhCZhezNf1czopLcxGRPbh27RoCAwMBAN988w1efPFFdOzYEZMmTcLy5ctljs40NRPA2GZARFJq1DqzAHD16lVcvXrVmrEQEdE9Wq0Wp0+fhl6vR0ZGBgYOHAgAuHnzJh+aQER0H7OK2dLSUsTFxaFFixbQarXQarVo0aIFpk6ditLSUolClAdTLxHJKTY2Fi+99BIiIiKgUCgQFRUFADh8+LDDrDNb0zPLkVkikpLJbQbXr19HZGQkLl26hOjoaHTu3BkAcPr0aaSlpSEzMxPfffedQy8jA3AtAyKyD/Pnz0dERAQKCwvx4osvQq1WA6h+zO0777wjc3SmcatZZ/Yue2aJSDomF7MLFy6ESqXCuXPnoNVq6+wbNGgQFi5cKC74TURElvnDH/5QZ1tMTIwMkTSOm0v1yCwfmkBEUjK5zeDLL7/E3//+9zqFLAAEBgbivffeq3f9WYfFb8WISAZDhw5FWVmZ+D4lJcWojevatWvo0qWLDJGZr6aYrdIzoRKRdEwuZq9cuYKuXbs2uD8iIgJFRUVWCUpOCi5nQEQy2rlzJ3Q6nfh+0aJFuH79uvj+7t27yM/PlyM0s6lcOTJLRNIzuZht0aIFLl682OD+CxcuwN/f3xoxERE1WbXXuHbkNa9V93pmq9gzS0QSMrmYHTx4MN59911UVVXV2afT6TBnzhw899xzVg1OTo771wcRkX3gyCwR2YJZE8D69OmDsLAwxMXFITw8HIIg4MyZM1i1ahV0Oh0+/fRTKWO1CTYZEJGcFApFnXYnR21/EntmOTJLRBIyuZht06YNDh06hDfffBOJiYniV18KhQIDBw7Ehx9+iKCgIMkCJSJqCgRBwMSJE8WluG7fvo0pU6agWbNmAGDUT2vvakZmqzgyS0QSMuuhCaGhofj2229x9epVZGdnIzs7G7/88gsyMjLQoUMHsy++f/9+jBgxAq1bt4ZCocCXX35ptF8QBMydOxetWrWCh4cHoqKi8OOPP5p9ncZw5D41InJcMTExCAgIgEajgUajwSuvvILWrVuL7wMCAjBhwgS5wzQJl+YiIlsweWT2fn5+fnj00UctvviNGzfQo0cPTJo0CaNHj66z/7333sOKFSuwfv16hIaGYs6cORg8eDBOnz4Nd3d3i69fHwf9No+InERqaqrcIViNODLLNgMiklCjillrGTJkCIYMGVLvPkEQsGzZMvz5z3/GyJEjAQCffPIJtFotvvzyS4wbN86WoRIRkZlU4sgsv+kiIumY1WZgSxcuXEBRUZH4PHIA0Gg06Nu3Lw4dOiRjZEREZApOACMiW5B1ZPZBah7AUPuJY1qt9oEPZ9DpdEYTJMrLyxt1fY4jEBFZhhPAiMgW7HZktrGSk5PFiRIajcbsFRYUXJyLiMgq3O49NIETwIhISnZbzAYGBgIAiouLjbYXFxeL++qTmJiIsrIy8VVYWChpnEREVD9OACMiW7DbYjY0NBSBgYHIzMwUt5WXl+Pw4cOIjIxs8HNqtRo+Pj5Gr8bgylxERJZRcWkuIrIBWYvZyspK5OXlIS8vD0D1pK+8vDwUFBRAoVAgPj4ef/3rX/HVV1/h5MmTmDBhAlq3bo1Ro0ZJFhOX5iIiZ/N7a3pLhSOzRGQLsk4AO3r0KJ5++mnxfUJCAoDqRcPT0tLw9ttv48aNG3j99ddRWlqKxx9/HBkZGZKtMUtE5Ix+b01vqYirGXBpLiKSkKzF7IABAx74pC2FQoGFCxdi4cKFNoyqmsD1DIjISTxoTW8p1YzMss2AiKRktz2zRETk2FRcZ5aIbMBu15klIiJ5WGu97t/aDFjMEpF0ODLbAK5mQERNlaXrdddwd6v+K0ZvENhqQESSYTFbC1czIKKmzlrrdbu7uYg/376jt1Z4RERG2GZARERG1Go11Gq15edxVUKhqP6m69YdPbzd3awQHRGRMRazDWCXARE5i8rKSvz000/i+5o1vf39/REcHCzZdRUKBdxdXXDrjh66O2wzICJpsJitRcE+AyJyMr+3preUPFTVxewtthkQkURYzBIRObnfW9NbSh73+mZvVbGYJSJpcAIYERFJpmZFA47MEpFUWMw2hE2zREQWq1nRgKsZEJFUWMzWwo5ZIiLr8WAxS0QSYzFLRESS8VDd65llMUtEEmEx2wCBfQZERBZTu9ZMAOPSXEQkDRaztXBlLiIi66kZmWWbARFJhcUsERFJxoOrGRCRxFjMNkCmJRmJiJyKp6p6OfObVXdljoSInBWL2VoUXM+AiMhqvNTVxWzlbRazRCQNFrNERCQZb/fqYraCxSwRSYTFbAPYZUBEZDlvdzcAQDmLWSKSCIvZWriaARGR9fw2MntH5kiIyFmxmCUiIsl4sc2AiCTGYrYBApczICKymM+9YrZSx2KWiKTBYrYWdhkQEVlPTc8s2wyISCosZomISDL3r2bAb7yISAosZomISDK+HioAwF2DwFYDIpIEi9kGcPyAiMhyHioXeKpcAADXKqtkjoaInBGL2drYNEtEZFXNvapHZ6/d0MkcCRE5IxazREQkqRZeagDAVY7MEpEEWMw2gPMUiIiso3mzmmKWI7NEZH0sZmtRsM+AiMiqWnpXtxlcreDILBFZH4tZIiKSlNbHHQBwpeyWzJEQkTNiMUtERJIK9vcEAPx87abMkRCRM2IxW4uCXQZERFZVU8wWXGcxS0TWx2KWiIgkVVPMXim7Bd1dvczREJGzYTH7AHz0IhGR5Vp6q+Hr6QaDAOQXVcgdDhE5GRaztbDLgIjIuhQKBbo9pAEAnLxUJnM0RORsWMwSEZHkerTxBQAcPn9d3kCIyOk4RDG7cuVKhISEwN3dHX379sWRI0dscl12GRCRs5Arj9Z4OrwlAGBvfglu32HfLBFZj90Xs//4xz+QkJCAefPm4dixY+jRowcGDx6MkpISSa6n4HIGRORkbJ1H6/NwkB8e8vVAxe272HSkwGbXJSLnZ/fF7JIlS/Daa68hNjYWXbp0wZo1a+Dp6YmPP/5Y7tCIiByCPeRRF6UCU55qBwBI+fYs0o8UoOL2HZtdn4icl6vcATxIVVUVcnNzkZiYKG5TKpWIiorCoUOH6v2MTqeDTvfb87/Ly8sbff3nlu+HkiO1RE2O2s0F2+L6yx2GVcidR+/3X33bIuuHq9h9phjvbDmJd7achI+7KzSebnBVKqFQAEqFAkpF9aPFmX6JHFtq7CNopfGQ/Dp2XcxevXoVer0eWq3WaLtWq8XZs2fr/UxycjIWLFjQ6Gt6u7uilcYdV8pu44fiykafh4gcl6fKRe4QrEaOPNoQF6UCa17phf89cAEbDxeg4PpNlN++i/Lbd61+LSKS3527tpl8ZNfFbGMkJiYiISFBfF9eXo6goCCTP+/mosTOmU/i+0vl0Bs4A4yoKVLafQOWtCzNow/i6qLElKfaY8pT7fHrjSpcu6FD2a27EAQBBgEwCAIMgsAJuEQSs8X/Yy291dJfBHZezLZo0QIuLi4oLi422l5cXIzAwMB6P6NWq6FWW/aH5+Puhsj2zS06BxGRPZArj5rCr5kKfs1Ukl+HiJybXY8/qFQq9O7dG5mZmeI2g8GAzMxMREZGyhgZEZFjYB4lImdn1yOzAJCQkICYmBj06dMHjz76KJYtW4YbN24gNjZW7tCIiBwC8ygROTO7L2bHjh2LX375BXPnzkVRUREefvhhZGRk1JnMQERE9WMeJSJnphAE526zLy8vh0ajQVlZGXx8fOQOh4ickLPnGWe/PyKSnyV5xq57ZomIiIiIHoTFLBERERE5LBazREREROSw7H4CmKVqWoKt9ThGIqLaavKLs05BYB4lIqlZkkedvpitqKgAAKs9vYaIqCEVFRXQaDRyh2F1zKNEZCuNyaNOv5qBwWDA5cuX4e3tDYVCYdJnah7dWFhY6PAzd3kv9suZ7qep34sgCKioqEDr1q2hdMJn4TKP8l7slTPdT1O/F0vyqNOPzCqVSrRp06ZRn/Xx8XH4X6gavBf75Uz305TvxRlHZGswj1bjvdgvZ7qfpnwvjc2jzjeEQERERERNBotZIiIiInJYLGbroVarMW/ePKjVarlDsRjvxX450/3wXqg2Z/pz5L3YL2e6H95L4zn9BDAiIiIicl4cmSUiIiIih8ViloiIiIgcFotZIiIiInJYLGaJiIiIyGGxmK1l5cqVCAkJgbu7O/r27YsjR47IHVIdycnJeOSRR+Dt7Y2AgACMGjUK+fn5Rsfcvn0bcXFxaN68Oby8vDBmzBgUFxcbHVNQUIBhw4bB09MTAQEB+OMf/4i7d+/a8lbqSElJgUKhQHx8vLjNke7l0qVLeOWVV9C8eXN4eHigW7duOHr0qLhfEATMnTsXrVq1goeHB6KiovDjjz8aneP69euIjo6Gj48PfH19MXnyZFRWVtr6VqDX6zFnzhyEhobCw8MD7du3x1/+8hej52bb6/3s378fI0aMQOvWraFQKPDll18a7bdW3P/+97/xxBNPwN3dHUFBQXjvvfckvS9HwTzKPGopZ8mlzKM2yqMCidLT0wWVSiV8/PHHwvfffy+89tprgq+vr1BcXCx3aEYGDx4spKamCqdOnRLy8vKEoUOHCsHBwUJlZaV4zJQpU4SgoCAhMzNTOHr0qPDYY48J/fr1E/ffvXtXiIiIEKKiooTjx48L33zzjdCiRQshMTFRjlsSBEEQjhw5IoSEhAjdu3cXZsyYIW53lHu5fv260LZtW2HixInC4cOHhfPnzws7d+4UfvrpJ/GYlJQUQaPRCF9++aVw4sQJ4fnnnxdCQ0OFW7duicc899xzQo8ePYTs7GzhX//6l9ChQwfh5Zdftum9CIIgJCUlCc2bNxd27NghXLhwQdi8ebPg5eUlLF++3O7v55tvvhHeffddYcuWLQIAYevWrUb7rRF3WVmZoNVqhejoaOHUqVPCpk2bBA8PD2Ht2rWS3pu9Yx5lHrWUM+VS5lHb5FEWs/d59NFHhbi4OPG9Xq8XWrduLSQnJ8sY1e8rKSkRAAhZWVmCIAhCaWmp4ObmJmzevFk85syZMwIA4dChQ4IgVP+SKpVKoaioSDxm9erVgo+Pj6DT6Wx7A4IgVFRUCGFhYcKuXbuEp556SkzCjnQvs2fPFh5//PEG9xsMBiEwMFD429/+Jm4rLS0V1Gq1sGnTJkEQBOH06dMCACEnJ0c85ttvvxUUCoVw6dIl6YKvx7Bhw4RJkyYZbRs9erQQHR0tCILj3E/tJGytuFetWiX4+fkZ/Y7Nnj1b6NSpk8R3ZN+YR5lHLeVMuZR51DZ5lG0G91RVVSE3NxdRUVHiNqVSiaioKBw6dEjGyH5fWVkZAMDf3x8AkJubizt37hjdS3h4OIKDg8V7OXToELp16watViseM3jwYJSXl+P777+3YfTV4uLiMGzYMKOYAce6l6+++gp9+vTBiy++iICAAPTs2RMfffSRuP/ChQsoKioyuheNRoO+ffsa3Yuvry/69OkjHhMVFQWlUonDhw/b7F4AoF+/fsjMzMQPP/wAADhx4gQOHDiAIUOGAHC8+6lhrbgPHTqEJ598EiqVSjxm8ODByM/Px6+//mqju7EvzKPMo9bgTLmUedQ2edTV0htyFlevXoVerzf6HxkAtFotzp49K1NUv89gMCA+Ph79+/dHREQEAKCoqAgqlQq+vr5Gx2q1WhQVFYnH1HevNftsKT09HceOHUNOTk6dfY50L+fPn8fq1auRkJCAP/3pT8jJycH06dOhUqkQExMjxlJfrPffS0BAgNF+V1dX+Pv72/y/yzvvvIPy8nKEh4fDxcUFer0eSUlJiI6OFmOtif9+9no/NawVd1FREUJDQ+uco2afn5+fJPHbM+ZR5lFrcKZcyjxqmzzKYtbBxcXF4dSpUzhw4IDcoTRKYWEhZsyYgV27dsHd3V3ucCxiMBjQp08fLFq0CADQs2dPnDp1CmvWrEFMTIzM0Znv888/x4YNG7Bx40Z07doVeXl5iI+PR+vWrR3yfogawjxqX5wplzKP2gbbDO5p0aIFXFxc6szuLC4uRmBgoExRPdjUqVOxY8cO7N27F23atBG3BwYGoqqqCqWlpUbH338vgYGB9d5rzT5byc3NRUlJCXr16gVXV1e4uroiKysLK1asgKurK7RarcPcS6tWrdClSxejbZ07d0ZBQYFRLA/6HQsMDERJSYnR/rt37+L69es2/z384x//iHfeeQfjxo1Dt27dMH78eMycORPJyclirDXx389e76eGteK2l987e8I8yjxqDc6US5lHbZNHWczeo1Kp0Lt3b2RmZorbDAYDMjMzERkZKWNkdQmCgKlTp2Lr1q3Ys2dPnSH63r17w83Nzehe8vPzUVBQIN5LZGQkTp48afSLtmvXLvj4+NRJIlJ69tlncfLkSeTl5YmvPn36IDo6WvzZUe6lf//+dZb2+eGHH9C2bVsAQGhoKAIDA43upby8HIcPHza6l9LSUuTm5orH7NmzBwaDAX379rXBXfzm5s2bUCqNU4SLiwsMBgMAx7ufGtaKOzIyEvv378edO3fEY3bt2oVOnTo1yRYDgHkUYB61BmfKpcyjNsqj5s9pc17p6emCWq0W0tLShNOnTwuvv/664OvrazS70x688cYbgkajEfbt2ydcuXJFfN28eVM8ZsqUKUJwcLCwZ88e4ejRo0JkZKQQGRkp7q9ZhmXQoEFCXl6ekJGRIbRs2VLWJWVq3D8LVxAc516OHDkiuLq6CklJScKPP/4obNiwQfD09BQ+++wz8ZiUlBTB19dX2LZtm/Dvf/9bGDlyZL1LmfTs2VM4fPiwcODAASEsLEyWpbliYmKEhx56SFxSZsuWLUKLFi2Et99+2+7vp6KiQjh+/Lhw/PhxAYCwZMkS4fjx48LPP/9stbhLS0sFrVYrjB8/Xjh16pSQnp4ueHp6cmku5lHmUQs5Uy5lHrVNHmUxW8sHH3wgBAcHCyqVSnj00UeF7OxsuUOqA0C9r9TUVPGYW7duCW+++abg5+cneHp6Ci+88IJw5coVo/NcvHhRGDJkiODh4SG0aNFCeOutt4Q7d+7Y+G7qqp2EHeletm/fLkRERAhqtVoIDw8X/ud//sdov8FgEObMmSNotVpBrVYLzz77rJCfn290zLVr14SXX35Z8PLyEnx8fITY2FihoqLClrchCIIglJeXCzNmzBCCg4MFd3d3oV27dsK7775rtISKvd7P3r176/1/JCYmxqpxnzhxQnj88ccFtVotPPTQQ0JKSoqk9+UomEeZRy3lLLmUedQ2eVQhCPc9hoKIiIiIyIGwZ5aIiIiIHBaLWSIiIiJyWCxmiYiIiMhhsZglIiIiIofFYpaIiIiIHBaLWSIiIiJyWCxmiYiIiMhhsZglaqSQkBAsW7ZM7jCIiBwW8yhZA4tZcggTJ07EqFGjAAADBgxAfHy8za6dlpYGX1/fOttzcnLw+uuv2ywOIiJLMI+Ss3KVOwAiuVRVVUGlUjX68y1btrRiNEREjod5lOwBR2bJoUycOBFZWVlYvnw5FAoFFAoFLl68CAA4deoUhgwZAi8vL2i1WowfPx5Xr14VPztgwABMnToV8fHxaNGiBQYPHgwAWLJkCbp164ZmzZohKCgIb775JiorKwEA+/btQ2xsLMrKysTrzZ8/H0Ddr8cKCgowcuRIeHl5wcfHBy+99BKKi4vF/fPnz8fDDz+MTz/9FCEhIdBoNBg3bhwqKiqk/UMjIroP8yg5Gxaz5FCWL1+OyMhIvPbaa7hy5QquXLmCoKAglJaW4plnnkHPnj1x9OhRZGRkoLi4GC+99JLR59evXw+VSoWDBw9izZo1AAClUokVK1bg+++/x/r167Fnzx68/fbbAIB+/fph2bJl8PHxEa83a9asOnEZDAaMHDkS169fR1ZWFnbt2oXz589j7NixRsedO3cOX375JXbs2IEdO3YgKysLKSkpEv1pERHVxTxKzoZtBuRQNBoNVCoVPD09ERgYKG7/8MMP0bNnTyxatEjc9vHHHyMoKAg//PADOnbsCAAICwvDe++9Z3TO+/vGQkJC8Ne//hVTpkzBqlWroFKpoNFooFAojK5XW2ZmJk6ePIkLFy4gKCgIAPDJJ5+ga9euyMnJwSOPPAKgOlmnpaXB29sbADB+/HhkZmYiKSnJsj8YIiITMY+Ss+HILDmFEydOYO/evfDy8hJf4eHhAKr/FV+jd+/edT67e/duPPvss3jooYfg7e2N8ePH49q1a7h586bJ1z9z5gyCgoLEBAwAXbp0ga+vL86cOSNuCwkJERMwALRq1QolJSVm3SsRkRSYR8lRcWSWnEJlZSVGjBiBxYsX19nXqlUr8edmzZoZ7bt48SKGDx+ON954A0lJSfD398eBAwcwefJkVFVVwdPT06pxurm5Gb1XKBQwGAxWvQYRUWMwj5KjYjFLDkelUkGv1xtt69WrF7744guEhITA1dX0X+vc3FwYDAa8//77UCqrv6j4/PPPf/d6tXXu3BmFhYUoLCwURxVOnz6N0tJSdOnSxeR4iIhsgXmUnAnbDMjhhISE4PDhw7h48SKuXr0Kg8GAuLg4XL9+HS+//DJycnJw7tw57Ny5E7GxsQ9MoB06dMCdO3fwwQcf4Pz58/j000/FCQ33X6+yshKZmZm4evVqvV+bRUVFoVu3boiOjsaxY8dw5MgRTJgwAU899RT69Olj9T8DIiJLMI+SM2ExSw5n1qxZcHFxQZcuXdCyZUsUFBSgdevWOHjwIPR6PQYNGoRu3bohPj4evr6+4khBfXr06IElS5Zg8eLFiIiIwIYNG5CcnGx0TL9+/TBlyhSMHTsWLVu2rDPxAaj+mmvbtm3w8/PDk08+iaioKLRr1w7/+Mc/rH7/RESWYh4lZ6IQBEGQOwgiIiIiosbgyCwREREROSwWs0RERETksFjMEhEREZHDYjFLRERERA6LxSwREREROSwWs0RERETksFjMEhEREZHDYjFLRERERA6LxSwREREROSwWs0RERETksFjMEhEREZHDYjFLRERERA7r/wGnwiJap69GnwAAAABJRU5ErkJggg==",
      "text/plain": [
       "<Figure size 800x300 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "# 価値反復法の途中経過を記録しておきます\n",
    "\n",
    "@jax.jit\n",
    "def compute_targ_Q(mdp: MDP, Q: np.ndarray):\n",
    "    S, A = Q.shape\n",
    "    max_Q = Q.max(axis=1).reshape(1, 1, S)\n",
    "    next_v = np.sum(mdp.P * max_Q, axis=-1)\n",
    "    assert next_v.shape == (S, A)\n",
    "    return mdp.rew + mdp.gamma * next_v\n",
    "\n",
    "compute_optimal_Q = lambda mdp: _compute_optimal_Q(mdp, mdp.S, mdp.A)\n",
    "\n",
    "\n",
    "plt.figure(figsize=(8, 3))\n",
    "optimality_gaps = []\n",
    "estimation_gaps = []\n",
    "Q_table = np.zeros((mdp.S, mdp.A))\n",
    "greedy_policy = compute_greedy_policy(Q_table)\n",
    "\n",
    "# >>>> Do value iteration >>>>\n",
    "for _ in range(1000):\n",
    "    estimation_gaps.append(jnp.abs(mdp.optimal_Q - Q_table).max())\n",
    "    optimality_gaps.append(jnp.abs(mdp.optimal_Q - pol_Q).max())\n",
    "    Q_table = compute_targ_Q(mdp, Q_table)\n",
    "    greedy_policy = compute_greedy_policy(Q_table)\n",
    "    pol_Q = compute_policy_Q(mdp, greedy_policy)\n",
    "# <<<< Do value iteration <<<<\n",
    "\n",
    "# >>>> Plot results >>>>\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(optimality_gaps)\n",
    "plt.xlabel(\"Iteration\")\n",
    "plt.ylabel(\"Optimality Gap\")\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(estimation_gaps)\n",
    "plt.xlabel(\"Iteration\")\n",
    "plt.ylabel(\"Estimation Gap\")\n",
    "# <<<< Plot results <<<<"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Array(0., dtype=float32),\n",
       " Array(0.02358246, dtype=float32),\n",
       " Array(0., dtype=float32),\n",
       " Array(0., dtype=float32),\n",
       " Array(0., dtype=float32),\n",
       " Array(0., dtype=float32),\n",
       " Array(0., dtype=float32),\n",
       " Array(0., dtype=float32),\n",
       " Array(0., dtype=float32),\n",
       " Array(0., dtype=float32)]"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "optimality_gaps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Array([49.366554, 49.36604 , 49.367073, 49.366554, 49.36604 , 49.36552 ,\n",
       "       49.366554, 49.36604 ], dtype=float32)"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mdp.optimal_Q[0]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "これは難しいMDPであることを証明しましょう。\n",
    "いくつか表記を導入します：\n",
    "\n",
    "* $\\mathcal{P}_\\beta$：plannerとシミュレータのインタラクションで誘導される確率測度\n",
    "* $i \\in\\{1, \\ldots, d-2\\}$について、\n",
    "$$\\operatorname{err}_i(\\pi, \\beta)=\\sum_{a \\in \\mathcal{A}} \\pi\\left(a \\mid s_0\\right) I_{\\operatorname{sgn}\\left(a_i\\right) \\neq \\operatorname{sgn}\\left(\\beta_i\\right)}$$"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "shumi-_oTXvTFg-py3.9",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "3fd07722de738cd9d533f64bafb7e99d08036d32b040e80da3eb397be78d09a1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
