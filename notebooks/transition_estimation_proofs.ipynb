{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# バンディットや強化学習の証明に出てくる集中不等式の扱い\n",
    "\n",
    "バンディットや強化学習の証明にはほぼ必ず何かしらの集中不等式が出てきます。\n",
    "しかし、どれも気をつけて適用しないと、何か間違った結果を導きかねません。\n",
    "このノートブックでは、他の理論系ノートブックに出てきた集中不等式の使い方をまとめてみます。(表記は各ノートブックに従い、少し簡素化した結果を載せます)\n",
    "\n",
    "**ノートブックと結果の一覧**\n",
    "\n",
    "* [UCBアルゴリズムのリグレットの証明](UCB_regret_proof.ipynb)：$\\left|\\widehat{\\mu}_a^t-\\mu_a\\right|$をバウンドしたい\n",
    "    * 時刻$t$時点のアーム$a$を引いた回数：$N_a^t=\\sum_{i=1}^{t-1} \\mathbf{1}\\left\\{A_i=a\\right\\}$\n",
    "    * 報酬の推定誤差：$\\widehat{\\mu}_a^t - \\mu_a = \\frac{1}{N_a^t}\\left(\\sum_{i=1}^{t-1} \\mathbf{1}\\left\\{A_i=a\\right\\} (r_i - \\mu_a) \\right)$\n",
    "    * $i$を含まない$i$までの履歴：$\\mathcal{H}_{<i}$\n",
    "    * マルチンゲール差分列：$X^i_a = \\mathbf{1}\\left\\{A_{i}=a\\right\\} (r_{i} - \\mu_a)$\n",
    "        * 決定的なアルゴリズムでは$\\mathcal{H}_{<i}$で条件付けられたとき、$i$番目のアームはいつも同じです。よって$\\mathbb{E}[X^i_a|\\mathcal{H}_{<i}]=0$なので、$X_a^i$はマルチンゲール差分列です。\n",
    "    * Hoeffding：固定された$a$と$t$について、$1-\\delta$以上で $\n",
    "\\left|\\widehat{\\mu}_a^t-\\mu_a\\right|=\\frac{1}{N_a^t}\\left|\\sum_{i=0}^{t-1} X_a^i\\right|\\leq \\square \\sqrt{\\frac{\\ln (1 / \\delta)}{N_a^t}}\n",
    "$\n",
    "\n",
    "* [UCB-VIアルゴリズムのリグレットの証明（弱）](UCB_VI_regret_proof.ipynb)：$\\left|\\left(\\widehat{P}_h^k\\left(\\cdot \\mid s_h, a_h\\right)-P^{\\star}\\left(\\cdot \\mid s_h, a_h\\right)\\right) \\cdot \\widehat{V}_{h+1}^{\\pi^k}\\right|$をバウンドしたい\n",
    "    * ここで、$\\widehat{P}_h^k$と$\\widehat{V}_{h+1}^{\\pi^k}$のどちらも確率変数。\n",
    "        * しかし、$\\widehat{V}_{h+1}^{\\pi^k}$の計算に使うサンプルは$\\widehat{P}_{h+1}^k$に依存しています。\n",
    "        * そして$\\widehat{P}_{h+1}^k$の計算の際に使ったサンプルは$x_{h, k}$に依存しています。\n",
    "        * つまり、$\\widehat{P}_h^k$と$\\widehat{V}_{h+1}^{\\pi^k}$は独立ではありません。\n",
    "    * 変わりに $\\left|\\left(\\widehat{P}_h^k\\left(\\cdot \\mid s_h, a_h\\right)-P^{\\star}\\left(\\cdot \\mid s_h, a_h\\right)\\right) \\cdot \\widehat{V}_{h+1}^{\\pi^k}\\right| \\leq\\left\\|\\hat{P}_h^k\\left(\\cdot \\mid s_h, a_h\\right)-P^{\\star}\\left(\\cdot \\mid s_h, a_h\\right)\\right\\|_1\\left\\|\\widehat{V}_{h+1}^{\\pi^k}\\right\\|_{\\infty}$を考えます。\n",
    "        * $\\left\\|\\hat{P}_h^k\\left(\\cdot \\mid s_h, a_h\\right)-P^{\\star}\\left(\\cdot \\mid s_h, a_h\\right)\\right\\|_1$のバウンドは[Near-optimal Regret Bounds for Reinforcement Learning](https://www.jmlr.org/papers/volume11/jaksch10a/jaksch10a.pdf)の式（４４）あたりが参考になります。\n",
    "\n",
    "* [UCB-VIアルゴリズムのリグレットの証明（強）](UCB_VI_regret_proof.ipynb)：$\\left|\\left(\\widehat{P}_h^k\\left(\\cdot \\mid s_h, a_h\\right)-P^{\\star}\\left(\\cdot \\mid s_h, a_h\\right)\\right) \\cdot \\left(\\widehat{V}_{h+1}^k-V_{h+1}^{\\star}\\right)\\right|$をバウンドしたい\n",
    "    * $\\left\\|\\hat{P}_h^k\\left(\\cdot \\mid s_h, a_h\\right)-P^{\\star}\\left(\\cdot \\mid s_h, a_h\\right)\\right\\|_1$の信頼区間は$S$次元で効率が悪いです。\n",
    "        * 変わりに$\\left|\\left(\\widehat{P}_h^k\\left(\\cdot \\mid s_h, a_h\\right)-P^{\\star}\\left(\\cdot \\mid s_h, a_h\\right)\\right) \\cdot \\left(\\widehat{V}_{h+1}^k-V_{h+1}^{\\star}\\right)\\right|$の信頼区間を直接出します。\n",
    "        * Bernsteinの不等式より、\n",
    "        $\n",
    "        \\left|\\widehat{P}_h^k\\left(s^{\\prime} \\mid s, a\\right)-P_h^{\\star}\\left(s^{\\prime} \\mid s, a\\right)\\right| \\leq \\sqrt{\\frac{2 P_h^{\\star}\\left(s^{\\prime} \\mid s, a\\right) L}{N_h^k(s, a)}}+\\frac{2 L}{N_h^k(s, a)},\n",
    "        $\n",
    "        が得られます。これは１次元の信頼区間になります。\n",
    "        * 任意の$f$を考えるときは $\\left|\\left(\\widehat{P}_h^k(\\cdot \\mid s, a)-P_h^{\\star}(\\cdot \\mid s, a)\\right)^{\\top} f\\right|\\leq \\sum_{s^{\\prime} \\in \\mathcal{S}}\\left|\\widehat{P}_h^k\\left(s^{\\prime} \\mid s, a\\right)-P_h^{\\star}(\\cdot \\mid s, a)\\right| f\\left(s^{\\prime}\\right)$とします。\n",
    "\n",
    "\n",
    "\n",
    "* [UCB-Hアルゴリズムのリグレットの証明](UCB_H_regret_proof.ipynb)： $\\left|\\sum_{h=1}^H \\sum_{k=1}^K\\left[\\left(\\mathbb{P}_h-\\hat{\\mathbb{P}}_h^k\\right)\\left(V_{h+1}^{\\star}-V_{h+1}^k\\right)\\right]\\left(x_h^k, a_h^k\\right)\\right|$をバウンドしたい\n",
    "    * $\\hat{\\mathbb{P}}_h^k$と$V_{h+1}^k$のどちらも確率変数です\n",
    "        * $V_{h+1}^k$の計算には${k-1}$までのデータしか使ってません。\n",
    "        * しかし、$\\hat{\\mathbb{P}}_{h}^k$の計算の際には$k$のデータしか使ってません。（モデルベースの場合は$k-1$までのデータも入ってたことに注意しましょう。）\n",
    "        * よって二つは独立になります。\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.6 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
