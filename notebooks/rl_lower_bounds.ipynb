{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 強化学習のサンプル効率の下界\n",
    "\n",
    "参考\n",
    "\n",
    "* [Reinforcement Learning: Theory and Algorithms](https://rltheorybook.github.io/)の５章\n",
    "\n",
    "強化学習はどれくらいのサンプル数があれば最適方策が求まるのでしょうか？「最低でも何個」必要になるかがわかると、アルゴリズムや問題設定の設計を見積もりやすくなります。\n",
    "今回は「最低でも何個」を調べるアプローチについて見ていきましょう。　\n",
    "\n",
    "特に、次の２つについて見ていきます：\n",
    "\n",
    "* Agnostic Learning：何らかの仮説集合に対して、その中から最良な仮説を見つけるために必要なサンプル効率はいくつか？\n",
    "* Linearly realizable values or policies：$d$-次元の特徴ベクトルが与えられ、最適価値関数が線形に表せる or 最適方策が線形にパラメータ化されているとします。このとき、$d$に依存するが、$S$や$A$に非依存なサンプル効率を達成することはできるのでしょうか？"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Agnostic Learning\n",
    "\n",
    "**表記**\n",
    "\n",
    "* 仮説集合：$\\mathcal{H}$\n",
    "    * $f\\in \\mathcal{H}$に対して方策$\\pi_f:\\mathcal{S}\\to\\mathcal{A}$を割り当てる\n",
    "* 方策の集合：$\\Pi=\\left\\{\\pi_f \\mid f \\in \\mathcal{H}\\right\\}$\n",
    "* Agnostic Learningの目標：$\\max _{\\pi \\in \\Pi} \\mathbb{E}_{s_0 \\sim \\mu} V^\\pi\\left(s_0\\right)$\n",
    "\n",
    "\n",
    "### 二値分類問題\n",
    "\n",
    "Agnostic learningのサンプル効率を見る前に、二値分類問題（$H=1$, $|\\mathcal{A}|=2$, $\\mathrm{label}(s)=a$のとき$r(s, a)=1$）のサンプル効率で練習してみましょう。\n",
    "* ClassifierのDomain：$\\mathcal{X}$（$\\mathcal{S}$のアナロジー）\n",
    "* $N$個のデータ：$\\left(x_i, y_i\\right)_{i=1}^N$\n",
    "    * $x_i \\in \\mathcal{X}$, $y_i \\in \\{0, 1\\}$\n",
    "* $h \\in \\mathcal{H}: \\mathcal{X} \\rightarrow\\{0,1\\}$\n",
    "* $\\mathbf{1}(h(x) \\neq y)$：$h(x)=y$なら０、それ以外で１を返す\n",
    "* $\\widehat{h}=\\arg \\min _{h \\in \\mathcal{H}} \\widehat{\\operatorname{err}}(h)$\n",
    "\n",
    "次の経験損失と真の損失を考えます。\n",
    "$$\\widehat{\\operatorname{err}}(h)=\\frac{1}{N} \\sum_{i=1}^N \\mathbf{1}\\left(h\\left(x_i\\right) \\neq y_i\\right), \\quad \\operatorname{err}(h)=\\mathbb{E}_{(X, Y) \\sim D} \\mathbf{1}(h(X) \\neq Y)$$\n",
    "\n",
    "これに対して、Hoeffdingの不等式を使えば\n",
    "$$\n",
    "|\\operatorname{err}(h)-\\widehat{\\operatorname{err}}(h)| \\leq \\sqrt{\\frac{1}{2 N} \\log \\frac{2}{\\delta}}\n",
    "$$\n",
    "\n",
    "が確率$1-\\delta$以上で成立します。Union Boundを使えば、次の「オッカムの剃刀」バウンドが簡単に導出されます：\n",
    "\n",
    "---\n",
    "\n",
    "**オッカムの剃刀**\n",
    "\n",
    "$\\mathcal{H}$が有限のとき、\n",
    "\n",
    "$$\n",
    "\\operatorname{err}(\\widehat{h}) \\leq \\min _{h \\in \\mathcal{H}} \\operatorname{err}(h)+\\sqrt{\\frac{2}{N} \\log \\frac{2|\\mathcal{H}|}{\\delta}}\n",
    "$$\n",
    "\n",
    "とくに、$N \\geq \\frac{2 \\log \\frac{2|\\mathcal{H}|}{\\delta}}{\\epsilon^2}$ならば、\n",
    "\n",
    "$$\\operatorname{err}(\\widehat{h}) \\leq \\min _{h \\in \\mathcal{H}} \\operatorname{err}(h)+\\epsilon$$\n",
    "\n",
    "が成り立つ。よく見ると、これは入力のサイズ$\\mathcal{X}$に依存していないことがわかります。\n",
    "\n",
    "---\n",
    "\n",
    "### 強化学習におけるオッカムの剃刀\n",
    "\n",
    "オッカムの剃刀の強化学習版を考えてみましょう。$N$個の軌跡をランダムな方策（$\\text {Unif }_\\mathcal{A}$）を実行して収集したとします。\n",
    "また、$\\pi$を決定的な方策とします。このとき、　\n",
    "\n",
    "$$\n",
    "V_0^\\pi(\\mu)=|\\mathcal{A}|^H \\cdot \\mathbb{E}_{\\tau \\sim \\operatorname{Pr}_{\\text {Unif }_\\mathcal{A}}}\\left[\\mathbf{1}\\left(\\pi\\left(s_0\\right)=a_0, \\ldots, \\pi\\left(s_{H-1}\\right)=a_{H-1}\\right) \\sum_{h=0}^{H-1} r\\left(s_h, a_h\\right)\\right]\n",
    "$$\n",
    "\n",
    "が成り立ちます。ここで、$\\operatorname{Pr}_{\\text {Unif }_\\mathcal{A}}$は$\\text {Unif }_\\mathcal{A}$における$\\tau=\\left(s_0, a_0, r_0, \\ldots s_{H-1}, a_{H-1}, r_{H-1}\\right)$の分布です。\n",
    "証明は簡単です。\n",
    "\n",
    "$$\n",
    "\\begin{aligned}\n",
    "V_0^\\pi(\\mu) & =\\mathbb{E}_{\\tau \\sim \\operatorname{Pr}_\\pi}\\left[\\sum_{h=0}^{H-1} r_h\\right] \\\\\n",
    "& =\\mathbb{E}_{\\tau \\sim \\operatorname{Pr}_{\\mathrm{Unif}_{\\mathcal{A}}}}\\left[\\frac{\\operatorname{Pr}_\\pi(\\tau)}{\\operatorname{Pr}_{\\mathrm{Unif}_{\\mathcal{A}}}(\\tau)} \\sum_{h=0}^{H-1} r_h\\right] \\\\\n",
    "& =|\\mathcal{A}|^H \\cdot \\mathbb{E}_{\\tau \\sim \\operatorname{Pr}_{\\mathrm{Unif}_{\\mathcal{A}}}}\\left[\\mathbf{1}\\left(\\pi\\left(s_0\\right)=a_0, \\ldots, \\pi\\left(s_{H-1}\\right)=a_{H-1}\\right) \\sum_{h=0}^{H-1} r_h\\right]\n",
    "\\end{aligned}\n",
    "$$\n",
    "\n",
    "ここで、最後の等式は$\\text {Unif }_\\mathcal{A}$が一様であることを利用しています。\n",
    "この等式はつまり、ランダムな方策があれば任意の方策の価値を普遍推定できることを表しています。そこで、$N$個の軌跡を使って次のように方策の価値を推定した時を考えてみましょう：\n",
    "\n",
    "$$\n",
    "\\widehat{V}_0^\\pi(\\mu)=\\frac{|\\mathcal{A}|^H}{N} \\sum_{n=1}^N \\mathbf{1}\\left(\\pi\\left(s_0^n\\right)=a_0^n, \\ldots \\pi\\left(s_{H-1}^n\\right)=a_{H-1}^n\\right) \\sum_{t=0}^{H-1} r\\left(s_t^n, a_t^n\\right)\n",
    "$$\n",
    "ここで、$\\left(s_0^n, a_0^n, r_1^n, s_1^n, \\ldots, s_{H-1}^n, a_{H-1}^n, r_{H-1}^n\\right)$は$n$番目の軌跡です。\n",
    "これに対して、次のバウンドが成立します：\n",
    "\n",
    "---\n",
    "\n",
    "**オッカムの剃刀（強化学習版）**\n",
    "\n",
    "$\\widehat{\\pi}=\\arg \\max _{\\pi \\in \\Pi} \\widehat{V}_0^\\pi(\\mu)$とします。このとき、確率$1-\\delta$以上で\n",
    "\n",
    "$$\n",
    "V_0^{\\widehat{\\pi}}(\\mu) \\geq \\max _{\\pi \\in \\Pi} V_0^\\pi(\\mu)-H|\\mathcal{A}|^H \\sqrt{\\frac{2}{N} \\log \\frac{2|\\Pi|}{\\delta}} .\n",
    "$$\n",
    "\n",
    "が成立します。証明は簡単です。まず、$|\\mathcal{A}|^H \\mathbf{1}\\left(\\pi\\left(s_0^n\\right)=a_0^n, \\ldots \\pi\\left(s_{H-1}^n\\right)=a_{H-1}^n\\right) \\sum_{t=0}^{H-1} r\\left(s_t^n, a_t^n\\right)$が$H|\\mathcal{A}^H$でバウンドされることに注意します。\n",
    "後はオッカムの剃刀の証明と同じです。\n",
    "\n",
    "また、$N \\geq H|\\mathcal{A}|^H \\frac{2 \\log (2|\\Pi| / \\delta)}{\\epsilon^2}$のとき、確率$1-\\delta$以上で$V_0^{\\widehat{\\pi}}\\left(s_0\\right) \\geq \\max _{\\pi \\in \\Pi} V_0^\\pi\\left(s_0\\right)-\\epsilon$が成立します。\n",
    "\n",
    "---\n",
    "\n",
    "ここから何がわかるでしょうか？Agnostic learningでは状態数に非依存なサンプル効率で学習ができますが、そのサンプル効率はホライゾンに指数的に依存していることがわかります。後で見ますが、これは更に仮定を置かなければ回避できません。\n",
    "\n",
    "\n",
    "TODO: 今までは$\\mathcal{H}$が有限の場合のみ対応していましたが、無限の場合でもVC次元を使えば対処できます。\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## サンプル効率の下界\n",
    "\n",
    "上のオッカムの剃刀で見たような$O(\\log |\\Pi|)$に依存したサンプル効率は、実はこれ以上の仮定を置かなければ、ホライゾンに指数依存であることは回避できません。これを見てみましょう。\n",
    "\n",
    "---\n",
    "\n",
    "**Agnostic Learningの下界（Generative Modelあり）**\n",
    "\n",
    "アルゴリズム$A$はgenerative modelを使って良いとします。また、$\\Pi$を$|\\Pi|=|\\mathcal{A}|^H$なる方策の集合とします。アルゴリズム$A$が次を満たすような方策を確率$1-\\delta$以上で返すとします（この$\\pi$は$\\Pi$になくても構いません）：\n",
    "\n",
    "$$\n",
    "V_0^\\pi(\\mu) \\geq \\max _{\\pi \\in \\Pi} V_0^\\pi(\\mu)-0.5\n",
    "$$\n",
    "\n",
    "このとき、$A$はこれを達成するために、最低$N \\geq c|\\mathcal{A}|^H$回はgenerative modelにクエリを投げる必要があるような$\\Pi$が存在します。\n",
    "\n",
    "これを満たすような$\\Pi$を構築してみましょう。\n",
    "$|\\mathcal{A}|$分岐なバランス木を考えます（状態数$|\\mathcal{A}|^H$かつ行動数$|\\mathcal{A}|$です）。\n",
    "また、方策のクラスとして、すべての$|\\mathcal{A}|^H$個の方策を考えます。\n",
    "また、報酬はどこかのリーフノードに単一で割り当てられているとします。\n",
    "\n",
    "このとき、$\\mathcal{A}^H$の中から当たりの方策を一つを見つけ出さない限り報酬の情報が得られないので、$|\\mathcal{A}|^H$のサンプル効率がかかることがすぐわかります。\n",
    "\n",
    "---\n",
    "\n",
    "このようなMDPの図を下に描画しておきます。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/svg+xml": "<?xml version=\"1.0\" encoding=\"UTF-8\" standalone=\"no\"?>\n<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n<!-- Generated by graphviz version 2.43.0 (0)\n -->\n<!-- Title: G Pages: 1 -->\n<svg width=\"495pt\" height=\"402pt\"\n viewBox=\"0.00 0.00 495.00 402.00\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n<g id=\"graph0\" class=\"graph\" transform=\"scale(1 1) rotate(0) translate(4 398)\">\n<title>G</title>\n<polygon fill=\"white\" stroke=\"transparent\" points=\"-4,4 -4,-398 491,-398 491,4 -4,4\"/>\n<g id=\"clust1\" class=\"cluster\">\n<title>cluster_1</title>\n<polygon fill=\"none\" stroke=\"blue\" points=\"261,-311 261,-386 345,-386 345,-311 261,-311\"/>\n<text text-anchor=\"middle\" x=\"303\" y=\"-370.8\" font-family=\"Times,serif\" font-size=\"14.00\">h=1</text>\n</g>\n<g id=\"clust2\" class=\"cluster\">\n<title>cluster_2</title>\n<polygon fill=\"none\" stroke=\"blue\" points=\"131,-203 131,-278 479,-278 479,-203 131,-203\"/>\n<text text-anchor=\"middle\" x=\"305\" y=\"-262.8\" font-family=\"Times,serif\" font-size=\"14.00\">h=2</text>\n</g>\n<g id=\"clust3\" class=\"cluster\">\n<title>cluster_H</title>\n<polygon fill=\"none\" stroke=\"blue\" points=\"8,-8 8,-83 371,-83 371,-8 8,-8\"/>\n<text text-anchor=\"middle\" x=\"189.5\" y=\"-67.8\" font-family=\"Times,serif\" font-size=\"14.00\">h=H</text>\n</g>\n<!-- s(1, 1) -->\n<g id=\"node1\" class=\"node\">\n<title>s(1, 1)</title>\n<ellipse fill=\"none\" stroke=\"black\" cx=\"303\" cy=\"-337\" rx=\"33.6\" ry=\"18\"/>\n<text text-anchor=\"middle\" x=\"303\" y=\"-333.3\" font-family=\"Times,serif\" font-size=\"14.00\">s(1, 1)</text>\n</g>\n<!-- s(2, 1) -->\n<g id=\"node2\" class=\"node\">\n<title>s(2, 1)</title>\n<ellipse fill=\"none\" stroke=\"black\" cx=\"173\" cy=\"-229\" rx=\"33.6\" ry=\"18\"/>\n<text text-anchor=\"middle\" x=\"173\" y=\"-225.3\" font-family=\"Times,serif\" font-size=\"14.00\">s(2, 1)</text>\n</g>\n<!-- s(1, 1)&#45;&gt;s(2, 1) -->\n<g id=\"edge1\" class=\"edge\">\n<title>s(1, 1)&#45;&gt;s(2, 1)</title>\n<path fill=\"none\" stroke=\"black\" d=\"M280.82,-323.36C262.56,-312.46 236.44,-295.72 216,-278 207.63,-270.75 199.3,-261.92 192.24,-253.83\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"194.78,-251.42 185.64,-246.07 189.45,-255.95 194.78,-251.42\"/>\n<text text-anchor=\"middle\" x=\"252.5\" y=\"-289.8\" font-family=\"Times,serif\" font-size=\"14.00\">a1</text>\n</g>\n<!-- s(2, 2) -->\n<g id=\"node3\" class=\"node\">\n<title>s(2, 2)</title>\n<ellipse fill=\"none\" stroke=\"black\" cx=\"259\" cy=\"-229\" rx=\"33.6\" ry=\"18\"/>\n<text text-anchor=\"middle\" x=\"259\" y=\"-225.3\" font-family=\"Times,serif\" font-size=\"14.00\">s(2, 2)</text>\n</g>\n<!-- s(1, 1)&#45;&gt;s(2, 2) -->\n<g id=\"edge2\" class=\"edge\">\n<title>s(1, 1)&#45;&gt;s(2, 2)</title>\n<path fill=\"none\" stroke=\"black\" d=\"M295.93,-318.97C288.86,-301.95 277.91,-275.55 269.76,-255.93\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"272.97,-254.53 265.91,-246.64 266.51,-257.22 272.97,-254.53\"/>\n<text text-anchor=\"middle\" x=\"293.5\" y=\"-289.8\" font-family=\"Times,serif\" font-size=\"14.00\">a2</text>\n</g>\n<!-- s(2, ...) -->\n<g id=\"node4\" class=\"node\">\n<title>s(2, ...)</title>\n<ellipse fill=\"none\" stroke=\"black\" cx=\"347\" cy=\"-229\" rx=\"36.29\" ry=\"18\"/>\n<text text-anchor=\"middle\" x=\"347\" y=\"-225.3\" font-family=\"Times,serif\" font-size=\"14.00\">s(2, ...)</text>\n</g>\n<!-- s(1, 1)&#45;&gt;s(2, ...) -->\n<g id=\"edge3\" class=\"edge\">\n<title>s(1, 1)&#45;&gt;s(2, ...)</title>\n<path fill=\"none\" stroke=\"black\" d=\"M310.07,-318.97C317.09,-302.05 327.96,-275.86 336.09,-256.28\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"339.35,-257.57 339.95,-246.99 332.88,-254.88 339.35,-257.57\"/>\n<text text-anchor=\"middle\" x=\"329\" y=\"-289.8\" font-family=\"Times,serif\" font-size=\"14.00\">...</text>\n</g>\n<!-- s(2, A) -->\n<g id=\"node5\" class=\"node\">\n<title>s(2, A)</title>\n<ellipse fill=\"none\" stroke=\"black\" cx=\"436\" cy=\"-229\" rx=\"35.19\" ry=\"18\"/>\n<text text-anchor=\"middle\" x=\"436\" y=\"-225.3\" font-family=\"Times,serif\" font-size=\"14.00\">s(2, A)</text>\n</g>\n<!-- s(1, 1)&#45;&gt;s(2, A) -->\n<g id=\"edge4\" class=\"edge\">\n<title>s(1, 1)&#45;&gt;s(2, A)</title>\n<path fill=\"none\" stroke=\"black\" d=\"M325.66,-323.39C344.33,-312.5 371.04,-295.77 392,-278 400.54,-270.76 409.05,-261.94 416.28,-253.85\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"419.12,-255.92 423.04,-246.08 413.84,-251.33 419.12,-255.92\"/>\n<text text-anchor=\"middle\" x=\"388\" y=\"-289.8\" font-family=\"Times,serif\" font-size=\"14.00\">aA</text>\n</g>\n<!-- s(H&#45;1, 1) -->\n<g id=\"node6\" class=\"node\">\n<title>s(H&#45;1, 1)</title>\n<ellipse fill=\"none\" stroke=\"black\" cx=\"173\" cy=\"-142\" rx=\"42.79\" ry=\"18\"/>\n<text text-anchor=\"middle\" x=\"173\" y=\"-138.3\" font-family=\"Times,serif\" font-size=\"14.00\">s(H&#45;1, 1)</text>\n</g>\n<!-- s(2, 1)&#45;&gt;s(H&#45;1, 1) -->\n<g id=\"edge5\" class=\"edge\">\n<title>s(2, 1)&#45;&gt;s(H&#45;1, 1)</title>\n<path fill=\"none\" stroke=\"black\" d=\"M173,-210.8C173,-199.16 173,-183.55 173,-170.24\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"176.5,-170.18 173,-160.18 169.5,-170.18 176.5,-170.18\"/>\n<text text-anchor=\"middle\" x=\"179\" y=\"-181.8\" font-family=\"Times,serif\" font-size=\"14.00\">...</text>\n</g>\n<!-- s(H, 1) -->\n<g id=\"node7\" class=\"node\">\n<title>s(H, 1)</title>\n<ellipse fill=\"lightgreen\" stroke=\"lightgreen\" cx=\"52\" cy=\"-34\" rx=\"36\" ry=\"18\"/>\n<text text-anchor=\"middle\" x=\"52\" y=\"-30.3\" font-family=\"Times,serif\" font-size=\"14.00\">s(H, 1)</text>\n</g>\n<!-- s(H&#45;1, 1)&#45;&gt;s(H, 1) -->\n<g id=\"edge6\" class=\"edge\">\n<title>s(H&#45;1, 1)&#45;&gt;s(H, 1)</title>\n<path fill=\"none\" stroke=\"black\" d=\"M151.26,-126.24C135.36,-115.07 113.59,-98.98 96,-83 87.71,-75.48 79.26,-66.59 72,-58.53\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"74.43,-56 65.19,-50.81 69.19,-60.63 74.43,-56\"/>\n<text text-anchor=\"middle\" x=\"129.5\" y=\"-94.8\" font-family=\"Times,serif\" font-size=\"14.00\">a1</text>\n</g>\n<!-- s(H, 2) -->\n<g id=\"node8\" class=\"node\">\n<title>s(H, 2)</title>\n<ellipse fill=\"none\" stroke=\"black\" cx=\"141\" cy=\"-34\" rx=\"36\" ry=\"18\"/>\n<text text-anchor=\"middle\" x=\"141\" y=\"-30.3\" font-family=\"Times,serif\" font-size=\"14.00\">s(H, 2)</text>\n</g>\n<!-- s(H&#45;1, 1)&#45;&gt;s(H, 2) -->\n<g id=\"edge7\" class=\"edge\">\n<title>s(H&#45;1, 1)&#45;&gt;s(H, 2)</title>\n<path fill=\"none\" stroke=\"black\" d=\"M167.86,-123.97C162.8,-107.2 154.99,-81.34 149.09,-61.81\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"152.37,-60.55 146.13,-51.99 145.67,-62.57 152.37,-60.55\"/>\n<text text-anchor=\"middle\" x=\"168.5\" y=\"-94.8\" font-family=\"Times,serif\" font-size=\"14.00\">a2</text>\n</g>\n<!-- s(H, ...) -->\n<g id=\"node9\" class=\"node\">\n<title>s(H, ...)</title>\n<ellipse fill=\"none\" stroke=\"black\" cx=\"233\" cy=\"-34\" rx=\"38.19\" ry=\"18\"/>\n<text text-anchor=\"middle\" x=\"233\" y=\"-30.3\" font-family=\"Times,serif\" font-size=\"14.00\">s(H, ...)</text>\n</g>\n<!-- s(H&#45;1, 1)&#45;&gt;s(H, ...) -->\n<g id=\"edge8\" class=\"edge\">\n<title>s(H&#45;1, 1)&#45;&gt;s(H, ...)</title>\n<path fill=\"none\" stroke=\"black\" d=\"M182.64,-123.97C192.36,-106.79 207.49,-80.07 218.63,-60.39\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"221.7,-62.07 223.58,-51.64 215.61,-58.62 221.7,-62.07\"/>\n<text text-anchor=\"middle\" x=\"208\" y=\"-94.8\" font-family=\"Times,serif\" font-size=\"14.00\">...</text>\n</g>\n<!-- s(H, A) -->\n<g id=\"node10\" class=\"node\">\n<title>s(H, A)</title>\n<ellipse fill=\"none\" stroke=\"black\" cx=\"326\" cy=\"-34\" rx=\"37.09\" ry=\"18\"/>\n<text text-anchor=\"middle\" x=\"326\" y=\"-30.3\" font-family=\"Times,serif\" font-size=\"14.00\">s(H, A)</text>\n</g>\n<!-- s(H&#45;1, 1)&#45;&gt;s(H, A) -->\n<g id=\"edge9\" class=\"edge\">\n<title>s(H&#45;1, 1)&#45;&gt;s(H, A)</title>\n<path fill=\"none\" stroke=\"black\" d=\"M201.7,-128.44C224.12,-117.95 255.47,-101.71 280,-83 289.32,-75.89 298.48,-66.87 306.15,-58.57\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"308.93,-60.71 312.99,-50.92 303.72,-56.04 308.93,-60.71\"/>\n<text text-anchor=\"middle\" x=\"274\" y=\"-94.8\" font-family=\"Times,serif\" font-size=\"14.00\">aA</text>\n</g>\n</g>\n</svg>\n",
      "text/plain": [
       "<graphviz.graphs.Digraph at 0x7f6e806bec40>"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from graphviz import Digraph\n",
    "\n",
    "g = Digraph('G')\n",
    "\n",
    "# h=1\n",
    "with g.subgraph(name='cluster_1') as c:\n",
    "    c.attr(color='blue')\n",
    "    c.node('s(1, 1)')\n",
    "    c.attr(label='h=1')\n",
    "\n",
    "# h=2\n",
    "with g.subgraph(name='cluster_2') as c:\n",
    "    c.attr(color='blue')\n",
    "    c.node('s(2, 1)')\n",
    "    c.node('s(2, 2)')\n",
    "    c.node('s(2, ...)')\n",
    "    c.node('s(2, A)')\n",
    "    c.attr(label='h=2')\n",
    "\n",
    "g.node('s(1, 1)')\n",
    "g.edge(\"s(1, 1)\", \"s(2, 1)\",label=\"a1\")\n",
    "g.edge(\"s(1, 1)\", \"s(2, 2)\",label=\"a2\")\n",
    "g.edge(\"s(1, 1)\", \"s(2, ...)\",label=\"...\")\n",
    "g.edge(\"s(1, 1)\", \"s(2, A)\",label=\"aA\")\n",
    "\n",
    "g.edge(\"s(2, 1)\", \"s(H-1, 1)\", label=\"...\")\n",
    "\n",
    "# h=H\n",
    "with g.subgraph(name='cluster_H') as c:\n",
    "    c.attr(color='blue')\n",
    "    c.node('s(H, 1)')\n",
    "    c.node('s(H, 2)')\n",
    "    c.node('s(H, ...)')\n",
    "    c.node('s(H, A)')\n",
    "    c.attr(label='h=H')\n",
    "\n",
    "g.node(\"s(H, 1)\", style=\"filled\", color=\"lightgreen\")\n",
    "g.edge(\"s(H-1, 1)\", \"s(H, 1)\",label=\"a1\")\n",
    "g.edge(\"s(H-1, 1)\", \"s(H, 2)\",label=\"a2\")\n",
    "g.edge(\"s(H-1, 1)\", \"s(H, ...)\",label=\"...\")\n",
    "g.edge(\"s(H-1, 1)\", \"s(H, A)\",label=\"aA\")\n",
    "\n",
    "g"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Linear Realizability\n",
    "\n",
    "さっきの仮定だけでは$H$に対して指数的なサンプル効率がかかってしまいました。次からより強い仮定を考えてみましょう。\n",
    "まずは$Q^\\pi$が線形近似可能である状況を考えてみます。実は、これから見るように、$Q^\\pi$の線形近似可能性だけではサンプル効率は良くなりません。\n",
    "\n",
    "以下ではoffline policy evaluationの設定を考えます。\n",
    "\n",
    "* ステップ$h$でのデータの分布：$\\left\\{\\mu_h\\right\\}_{h=0}^{H-1}$\n",
    "    * $\\mu_h \\in \\Delta\\left(\\mathcal{S}_h \\times \\mathcal{A}\\right)$ \n",
    "* エージェントに与えられるデータセット：$\\left\\{D_h\\right\\}_{h=0}^{H-1}$\n",
    "    * $D_h$は独立したサンプルで構築される: $\\left(s, a, r, s^{\\prime}\\right) \\in\\mathcal{S}_h \\times \\mathcal{A} \\times \\mathbb{R} \\times \\mathcal{S}_{h+1}$\n",
    "    * $(s, a) \\sim \\mu_h, r \\sim r(s, a), s^{\\prime} \\sim P(s, a)$\n",
    "    * エージェントは$\\left\\{D_h\\right\\}_{h=0}^{H-1}$を使って$V^\\pi$を近似するのが目標\n",
    "* 方策：$\\pi: \\mathcal{S} \\rightarrow \\Delta(\\mathcal{A})$\n",
    "* 特徴ベクトル：$\\phi: \\mathcal{S} \\times \\mathcal{A} \\rightarrow \\mathbb{R}^d$\n",
    "\n",
    "また、次の仮定を考えます：\n",
    "\n",
    "---\n",
    "\n",
    "**仮定：$Q^\\pi$の線形実現可能性**\n",
    "\n",
    "任意の方策$\\pi$について、次を満たす$\\theta_0^\\pi, \\ldots \\theta_{H-1}^\\pi \\in \\mathbb{R}^d$が存在する：\n",
    "\n",
    "$$Q_h^\\pi(s, a)=\\left(\\theta_h^\\pi\\right)^{\\top} \\phi(s, a)$$\n",
    "\n",
    "この仮定は**全ての**方策が線形に実現可能という点で、結構強い仮定であることに注意しましょう。\n",
    "\n",
    "---\n",
    "\n",
    "---\n",
    "\n",
    "**仮定：Coverage**\n",
    "\n",
    "任意の$(s, a)$について、$\\|\\phi(s, a)\\|_2 \\leq 1$とします。また、任意の$h\\in [H]$について、$\\mu$は次を満たすとします：\n",
    "\n",
    "$$\\mathbb{E}_{(s, a) \\sim \\mu_h}\\left[\\phi(s, a) \\phi(s, a)^{\\top}\\right]=\\frac{1}{d} I$$\n",
    "\n",
    "これはデータの分布$\\mu_h$がD-optimal designであるという仮定と等価であることに注意しましょう。\n",
    "また、対角行列の成分は固有値なので、この行列の最小の固有値は$1/d$です。\n",
    "さらに、任意のデータ分布$\\widetilde{\\mu}_h$についての最小の固有値の最大値は$1/d$になります（$\\|\\phi(s, a)\\|_2 \\leq 1$なので$\\sigma_{\\min }\\left(\\mathbb{E}_{(s, a) \\sim \\widetilde{\\mu}_h}\\left[\\phi(s, a) \\phi(s, a)^{\\top}\\right]\\right)$が成り立つためです）。\n",
    "\n",
    "---\n",
    "\n",
    "Coverageの仮定と線形実現性の仮定から、通常の最小二乗法で$Q_h^\\pi$が良く近似できることが保証されています。しかし、実はこの仮定だけでは強化学習は効率よく解けません。\n",
    "\n",
    "---\n",
    "\n",
    "**定理： Exponential Lower Bound**\n",
    "\n",
    "仮定：Coverageが成り立っているとします。また、方策と特徴ベクトルを入力として受けるアルゴリズムを考えます。\n",
    "このとき、どんなアルゴリズムに対しても、次を満たすような実現可能性の仮定を満たすMDPが存在します。\n",
    "\n",
    "「どんな方策$\\pi: \\mathcal{S} \\rightarrow \\Delta(\\mathcal{A})$に対しても、確率$0.9$以上で$\\pi$の価値を定数誤差で吐き出すために$\\Omega\\left((d / 2)^H\\right)$のサンプルが必要になる。」\n",
    "\n",
    "---\n",
    "\n",
    "これは方策評価についての話ですが、簡単な例によって一般のOffline RLが最適方策を近似する場合についても成り立つことがわかります。\n",
    "例えば、初期状態で行動$a_1$を選択し、報酬$0.5$を受け取って終了するとします。\n",
    "一方、$a_2$を選択するとムズMDPに遷移するとします。\n",
    "このとき、準最適性が$0.5$以下になるような方策を獲得するには、ムズMDPの方策を$0.5$以下の精度で評価しなければなりません。\n",
    "よって、方策評価がちゃんとできないと最適方策もわかりません。\n",
    "\n",
    "このムズMDPを構築してみましょう。"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* $\\hat{d}=d/2$\n",
    "* 行動集合：$\\mathcal{A}=\\left\\{a_1, a_2\\right\\}$\n",
    "* $h$での状態集合（$\\hat{d}+1$個）：$s_h^1, s_h^2, \\ldots, s_h^{\\hat{d}}$ and $s_h^{\\hat{d}+1}$\n",
    "* 任意の$h \\in\\{0,1, \\ldots, H-2\\}$と$c \\in\\{1,2, \\ldots, \\hat{d}+1\\}$について、\n",
    "$$\n",
    "P\\left(s \\mid s_h^c, a\\right)= \\begin{cases}1 & s=s_{h+1}^{\\hat{d}+1}, a=a_1 \\\\ 1 & s=s_{h+1}^c, a=a_2 \\\\ 0 & \\text { else }\\end{cases}\n",
    "$$\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Linear MDP\n",
    "\n",
    "* 参考\n",
    "Linear MDPの下界を求めてみます。"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('shumi-VTLwuKSy-py3.9')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "d6b7cac5e0d2ff733f340da4d53ae5ecfef7f7ad39623f5982b029a09306b36b"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
